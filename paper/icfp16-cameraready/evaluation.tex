% \section{Evaluation: Recasting Type Errors as Runtime Errors}
\section{Evaluation}
\label{sec:evaluation}

We have implemented a prototype of our search procedure and trace
visualization for a purely functional subset of \ocaml\ --- with
polymorphic types and records, but no modules, objects, or polymorphic
variants --- in a tool called \nanomaly.
%
We treat explicit type signatures, \eg @(x : int)@, as
primitive operations that narrow the type of the wrapped value.
%
In our implementation we instantiated \gensym\ with a simple random
generation of values, which we will show suffices for the majority of
type errors.

\paragraph{Evaluation Goals}
%
There are three questions we seek to answer with our evaluation:
%
\begin{enumerate}
\item \emphbf{Witness Coverage}
      How many ill-typed programs can we find witnesses for?
\item \emphbf{Witness Complexity}
      How \emph{complex} are the traces produced by the witnesses?
\item \emphbf{Witness Utility}
      How \emph{helpful} are the witnesses and traces in debugging type errors?
\end{enumerate}

\paragraph{Benchmarks}
We answer the first two questions on two sets of ill-typed programs,
\ie\ programs that were rejected by the \ocaml\ compiler because of a
type error.
%
The first dataset comes from the Spring 2014 undergraduate Programming
Languages course at UC San Diego.
%
We recorded each interaction with the \ocaml\ top-level system over the
course of the first three assignments (IRB
% \# hidden for blind review),
\#140608),
from which we extracted \ucsdsize\ distinct, ill-typed \ocaml\ programs.
%
The second dataset --- widely used in the literature --- comes from a
graduate-level course at the University of Washington~\cite{Lerner2006-pj},
from which we extracted 284 ill-typed programs.
%
Both datasets contain relatively small programs, the largest being 348
SLoC; however, they demonstrate a variety of functional programming
idioms including (tail) recursive functions, higher-order functions,
polymorphic data types, and expression evaluators.


\subsection{Witness Coverage}
\label{sec:eval:witness-coverage}
%
We ran our search algorithm on each program for 1,000 iterations, with
the entry point set to the function that \ocaml\ had identified as
containing a type error.
%
Due to the possibility of non-termination we set a timeout of one minute
total per program.
%
% Due to the possibility of non-termination we set a limit on the number
% of reductions to perform, increasing in 500-step increments from 500
% steps to 3,000 steps total.
%
We also added a na{\"\i}ve check for infinite recursion; at each recursive
function call we check whether the new arguments are identical to the
current arguments.
%
If so, the function cannot possibly terminate and we report an error.
%
While not a \emph{type error}, infinite recursion is still a clear bug
in the program, and thus valuable feedback for the user.

\begin{figure*}[ht]
\centering
\begin{minipage}{\linewidth}
\centering
\includegraphics[width=0.49\linewidth]{coverage.png}
% \end{minipage}
% \begin{minipage}{\linewidth}
\includegraphics[width=0.49\linewidth]{distrib.png}
\end{minipage}
% \vspace{-8ex}
\caption{Results of our coverage testing and the distribution of test
  outcomes. Our random search successfully finds witnesses for 79--85\% of
  the programs in under one second, improving slightly to 87\% in under
  10 seconds. In both datasets we detect actual type errors about 82\%
  of the time, unbound variables or constructors 3--4\% of the time, and
  diverging loops 2--3\% of the time. For the remaining 11--12\% of the
  programs we are unable to provide any useful feedback.  }
\label{fig:results-witness}
\end{figure*}

\paragraph{Results}
\label{sec:results-witness}
The results of our experiments are summarized in
Figure~\ref{fig:results-witness}.
%
In both datasets our tool was able to find a witness for 83\% of the
programs in under one second, \ie\ fast enough to be integrated as a
compile-time check. If we extend our tolerance to a 10 second timeout,
we hit a maximum of 87\% coverage.
%
Interestingly, while the vast majority of witnesses corresponded to a
type-error, as expected, 3--4\% triggered an unbound variable error (even
though \ocaml\ reported a type error) and 2--3\% triggered an infinite
recursion error.
%
For the remaining 12\% of programs we were unable to provide any useful
feedback as they either completed 1,000 tests successfully, or timed out
after one minute.
%
% XX programs were deemed safe and XX timed out even at 3,000 steps, \ie
% we could not provide any useful feedback for XX\% of the total programs.
%
While a more advanced search procedure, \eg\ dynamic-symbolic execution,
could likely trigger more of the type errors, our experiments show that
type errors are coarse enough (or that novice programs are \emph{simple}
enough) that these techniques are not necessary.


\subsection{Witness Complexity}
\label{sec:trace-complexity}

For each of the ill-typed programs for which we could
find a witness, we measure the complexity of the generated
trace according to two metrics.

% \paragraph{Metrics} Thus, our two metrics are:
% size of the full trace,
% \ie the number of small-step reductions, and the size of the jump-compressed
% version of the trace.
%
\begin{enumerate}
\item \emphbf{Single-step Metric} The size of the trace after expanding
  all of the single-step edges from the witness to the stuck term, and
  % This can be thought of as a worst-case
  % complexity, \ie ``How big is the fully-expanded trace?''
\item \emphbf{Jump-compressed Metric} The size of the jump-compressed trace.
\end{enumerate}


% \item \ES{others?}
%
\begin{figure*}[ht]
\centering
\includegraphics[width=0.49\linewidth]{trace_size_step.png}
\includegraphics[width=0.49\linewidth]{trace_size_jump.png}
\caption{Complexity of the generated traces. 81\% of the combined traces
  have a jump complexity of at most 10, with an average complexity of 7
  and a median of 5.}
\label{fig:results-complexity}
\end{figure*}
%

\paragraph{Results}
\label{sec:results-complexity}
The results of the experiment are summarized in
Figure~\ref{fig:results-complexity}.
%
The average number of single-step reductions per trace is 31 for the
\ucsdbench\ dataset (35 for the \uwbench\ dataset) with a maximum of
2,745 (986 for \uwbench) and a median of 17 (also 17 for \uwbench).
%
The average number of jumps per trace is 7 (also 7 for \uwbench) with a
maximium of 353 (185 for \uwbench) and a median of 4 (also 4 for
\uwbench).
%
In both datasets 80\% or more traces have at most 10 jumps.
%

\input{gallery2}

\subsection{Measuring Witness Utility}
\label{sec:user-study}
Finally, to test the explanatory power of our jump-compressed traces, we
ran a user study (IRB \#XXXX) at the University of Virginia (UVA).
%
We included four problems in an exam in the Spring session of UVA's
undergraduate Programming Languages course (CS XXX).
%
The problems presented the students with ill-typed \ocaml\ programs and
asked them to
%
(1) \emph{explain} the type error, and
%
(2) \emph{fix} the type error.
%
For each problem the student would be given the ill-typed program and
either \ocaml's error message or \toolname's jump-compressed trace.
%
The four problems assigned to the students were the @sumList@,
@digitsOfInt@, and @wwhile@ programs from \S~\ref{sec:advantage-traces},
as well as the following @append@ program
%
\begin{ecode}
  let append x l =
    match x with
    | []   -> l
    | h::t -> h :: t :: l
\end{ecode}
%
which triggers an occurs-check error in the ``cons'' case.
%
We then instructed four annotators (one of whom is an author, the other
three are teaching assistants at UCSD) to classify the answers as
correct or incorrect.

We performed an inter-rater reliability (IRR) analysis to determine the
degree to which the annotators consistently graded the exams.
%
As we had more than two annotators assigning nominal (``correct'' or
``incorrect'') ratings we used Fleiss' kappa~\cite{Fleiss1971-du} to
measure IRR.\@
%
Fleiss' kappa is measured on a scale from $1$, indicating total
agreement, to $-1$, indicating total disagreement, with $0$ indicating
random agreement.

\paragraph{Results}
%
We collected exams from 60 students, though due to the nature of the
study not every student completed every problem.
%
Figure~\ref{fig:results-user-study} summarizes a single annotator's
results, which show that students given \toolname's jump-compressed
trace were consistently more likely to correctly explain and fix the
type error than those given \ocaml's error message.
%
The measured kappa values were $\kappa = 0.72$ for the explanations and
$\kappa = 0.83$ for the fixes; while there is no formal notion for what
consititutes strong agreement~\cite{Krippendorff2012-wd}, kappa values
above $0.60$ are often called ``substantial''
agreement~\cite{Landis1977-ey}.
%
\begin{figure*}[ht]
\centering
\includegraphics[width=0.49\linewidth]{user-study-reason.png}
\includegraphics[width=0.49\linewidth]{user-study-fix.png}
\caption{A classification of students' explanations and fixes for type
  errors, given either \ocaml's error % message
  or \toolname's
  jump-compressed trace. The students given \toolname's jump-compressed
  trace consistently scored better than those given \ocaml's type
  error.}
\label{fig:results-user-study}
\end{figure*}
%

\subsection{Discussion}
\label{sec:discussion}

To summarize, our experiments demonstrate that \nanomaly finds witnesses
to type errors: (1) with high coverage in a timespan amenable to
compile-time analysis, (2) with traces that have a low average
complexity of 7 jumps, and (3) that are more helpful to novice
programmers than traditional type error messages.

There are, of course, drawbacks to our approach. Four that stand out
are: (1) coverage limits due to random generation, (2) the inability to
handle certain instances of infinite types, (3) dealing with an
explosion in the size of generated traces, and (4) handling ad-hoc
polymorphism.

\paragraph{Random Generation}
Random test generation has difficulty generating highly constrained
values, \eg\ red-black trees or a pair of equal integers. If the type
error is hidden behind a complex branch condition \nanomaly\ may not be
able to trigger it. Exhaustive testing and dynamic-symbolic execution
can address this short-coming by performing an exhaustive search for
inputs (\emph{resp}.\ paths through the program). As our experiments
show, however, novice programs do not appear to require more advanced
search techniques, likely because the novice programs tend to be simple.

\paragraph{Infinite Types}
Our implementation does check for infinite types inside \forcesym, but
there are some degenerate cases where it is unable to detect
them. Consider, the following buggy @replicate@
%
\begin{code}
  let rec replicate n x =
    if n <= 0 then
      []
    else
      replicate (n-1) [x]
\end{code}
%
This code produces a nested list (with @n@ levels of nesting) containing
a single copy of @x@, instead of a list with @n@ copies of @x@. \ocaml\
detects a cyclic \hbox{@'a = 'a list@} constraint in the recursive call
and throws a type error, whereas \nanomaly\ happily % recurses @n@ times to
produces the nested list.  Strictly speaking, this function itself cannot
``go wrong'', the program would not get stuck until a \emph{client}
attempted to use the result expecting a flat list. But this is not very
satisfying as @replicate@ is clearly to blame. Furthermore, in our
experience, infinite-type errors are often difficult to %some of the more difficult ones to
debug (and to explain to novices), so better support for this scenario
would be useful.

\paragraph{Trace Explosion}
Though the average complexity of our generated traces is low in terms of
jumps, there are some extreme outliers.
%
We cannot reasonably expect a novice user to explore a trace containing
50+ terms and draw a conclusion about which pieces contributed to the
bug in their program.
%
Enhancing our visualization to slice out program paths relevant to
specific values~\cite{Perera2012-dy}, would likely help alleviate this
issue, allowing users to highlight a confusing value and ask: ``Where
did this come from?''

\paragraph{Ad-hoc Polymorphism}
Our approach can only support ad-hoc polymorphism (\eg\ type-classes in
\haskell\ or polymorphic comparison functions in \ocaml) in limited cases
where we have enough typing information at the call-site to resolve the
overloading. For example, consider the @n <= 0@ test in our @fac@ example.
@<=@ is polymorphic in \ocaml, but in this case we can make progress because
the literal @0@ is not. If we parameterized @fac@ by a lower bound, \eg
%
\begin{code}
  let rec fac n m =
    if n <= m then
      1
    else
      n * fac (n - 1) m
\end{code}
%
and called @fac@ with two holes, we would get stuck at the @n <= m@
test; not because of a type error, but because all we know about
@n@ and @m@ at that point is that they must have the same (unknown)
type.

This issue is uncommon in \ocaml\ (we did not detect a single instance
of it across all of our benchmarks), but it would surely be exacerbated
by a language like \haskell, which makes heavy use of overloading. We
suspect that dynamic-symbolic execution would allow us to handle ad-hoc
polymorphism, but defer a proper treatment to future work.

% \begin{itemize}
% \item benchmarks: our data + seminal data
% \item both cases: \textbf{random} search sufficient to trigger runtime crash in 80\% of programs
% \item how many of the ``safe'' programs are actually safe??
% \end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
%!TEX root = main.tex
