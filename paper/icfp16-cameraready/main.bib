
@incollection{jeuring_ask-elle:_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Ask-{Elle}: {A} {Haskell} {Tutor}},
	copyright = {©2012 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-33262-3 978-3-642-33263-0},
	shorttitle = {Ask-{Elle}},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-33263-0_42},
	abstract = {In this demonstration we will introduce Ask-Elle, a Haskell tutor. Ask-Elle supports the incremental development of Haskell programs. It can give hints on how to proceed with solving a programming exercise, and feedback on incomplete student programs. We will show Ask-Elle in action, and discuss how a teacher can configure its behaviour.},
	language = {en},
	number = {7563},
	urldate = {2015-08-13},
	booktitle = {21st {Century} {Learning} for 21st {Century} {Skills}},
	publisher = {Springer Berlin Heidelberg},
	author = {Jeuring, Johan and Gerdes, Alex and Heeren, Bastiaan},
	editor = {Ravenscroft, Andrew and Lindstaedt, Stefanie and Kloos, Carlos Delgado and Hernández-Leo, Davinia},
	year = {2012},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Communication Networks, Data Mining and Knowledge Discovery, Information Storage and Retrieval, Information Systems Applications (incl. Internet), User Interfaces and Human Computer Interaction},
	pages = {453--458},
	file = {jeuring_et_al_2012_ask-elle.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/CWNK66C8/jeuring_et_al_2012_ask-elle.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/82XK9SB4/10.html:text/html}
}

@article{korel_dynamic_1988,
	title = {Dynamic program slicing},
	volume = {29},
	issn = {0020-0190},
	url = {http://www.sciencedirect.com/science/article/pii/0020019088900543},
	doi = {10.1016/0020-0190(88)90054-3},
	abstract = {A dynamic program slice is an executable subset of the original program that produces the same computations on a subset of selected variables and inputs. It differs from the static slice (Weiser, 1982, 1984) in that it is entirely defined on the basis of a computation. The two main advantages are the following: Arrays and dynamic data structures can be handled more precisely and the size of slice can be significantly reduced, leading to a finer localization of the fault. The approach is being investigated as a possible extension of the debugging capabilities of STAD, a recently developed System for Testing and Debugging (Korel and Laski, 1987; Laski, 1987).},
	number = {3},
	urldate = {2015-07-24},
	journal = {Information Processing Letters},
	author = {Korel, Bogdan and Laski, Janusz},
	month = oct,
	year = {1988},
	keywords = {control dependence, data dependence, debugging, dynamic slice, slicing, trajectory},
	pages = {155--163},
	file = {korel_laski_1988_dynamic_program_slicing.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/MXE37AJZ/korel_laski_1988_dynamic_program_slicing.pdf:application/pdf;ScienceDirect Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/IDFD5763/0020019088900543.html:text/html}
}

@inproceedings{marceau_measuring_2011,
	address = {New York, NY, USA},
	series = {{SIGCSE} '11},
	title = {Measuring the {Effectiveness} of {Error} {Messages} {Designed} for {Novice} {Programmers}},
	isbn = {978-1-4503-0500-6},
	url = {http://doi.acm.org/10.1145/1953163.1953308},
	doi = {10.1145/1953163.1953308},
	abstract = {Good error messages are critical for novice programmers. Re-cognizing this, the DrRacket programming environment provides a series of pedagogically-inspired language subsets with error messages customized to each subset. We apply human-factors research methods to explore the effectiveness of these messages. Unlike existing work in this area, we study messages at a fine-grained level by analyzing the edits students make in response to various classes of errors. We present a rubric (which is not language specific) to evaluate student responses, apply it to a course-worth of student lab work, and describe what we have learned about using the rubric effectively. We also discuss some concrete observations on the effectiveness of these messages.},
	urldate = {2015-09-24},
	booktitle = {Proceedings of the 42Nd {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Marceau, Guillaume and Fisler, Kathi and Krishnamurthi, Shriram},
	year = {2011},
	keywords = {error messages, novice programmers, user-studies},
	pages = {499--504},
	file = {marceau_et_al_2011_measuring_the_effectiveness_of_error_messages_designed_for_novice_programmers.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/25Z35SRR/marceau_et_al_2011_measuring_the_effectiveness_of_error_messages_designed_for_novice_programmers.pdf:application/pdf}
}

@inproceedings{marceau_mind_2011,
	address = {New York, NY, USA},
	series = {Onward! 2011},
	title = {Mind {Your} {Language}: {On} {Novices}' {Interactions} with {Error} {Messages}},
	isbn = {978-1-4503-0941-7},
	shorttitle = {Mind {Your} {Language}},
	url = {http://doi.acm.org/10.1145/2048237.2048241},
	doi = {10.1145/2048237.2048241},
	abstract = {Error messages are one of the most important tools that a language offers its programmers. For novices, this feed-back is especially critical. Error messages typically contain both a textual description of the problem and an indication of where in the code the error occurred. This paper reports on a series of studies that explore beginning students' inter-actions with the vocabulary and source-expression high-lighting in DrRacket. Our findings demonstrate that the error message significantly fail to convey information accurately to students, while also suggesting alternative designs that might address these problems.},
	urldate = {2015-09-24},
	booktitle = {Proceedings of the 10th {SIGPLAN} {Symposium} on {New} {Ideas}, {New} {Paradigms}, and {Reflections} on {Programming} and {Software}},
	publisher = {ACM},
	author = {Marceau, Guillaume and Fisler, Kathi and Krishnamurthi, Shriram},
	year = {2011},
	keywords = {beginner-friendly ides, error message design, novice programmers, user-studies},
	pages = {3--18},
	file = {marceau_et_al_2011_mind_your_language.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/Q4342API/marceau_et_al_2011_mind_your_language.pdf:application/pdf}
}

@inproceedings{crestani_experience_2010,
	address = {New York, NY, USA},
	series = {{ICFP} '10},
	title = {Experience {Report}: {Growing} {Programming} {Languages} for {Beginning} {Students}},
	isbn = {978-1-60558-794-3},
	shorttitle = {Experience {Report}},
	url = {http://doi.acm.org/10.1145/1863543.1863576},
	doi = {10.1145/1863543.1863576},
	abstract = {A student learning how to program learns best when the programming language and programming environment cater to her specific needs. These needs are different from the requirements of a professional programmer. Consequently, the design of teaching languages poses challenges different from the design of professional languages. Using a functional language by itself gives advantages over more popular, professional languages, but fully exploiting these advantages requires careful adaptation to the needs of the students' as-is, these languages do not support the students nearly as well as they could. This paper describes our experience adopting the didactic approach of How to Design Programs, focussing on the design process for our own set of teaching languages. We have observed students as they try to program as part of our introductory course, and used these observations to significantly improve the design of these languages. This paper describes the changes we have made, and the journey we took to get there.},
	urldate = {2015-09-24},
	booktitle = {Proceedings of the 15th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Crestani, Marcus and Sperber, Michael},
	year = {2010},
	keywords = {introductory, Programming},
	pages = {229--234},
	file = {crestani_sperber_2010_experience_report.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/U8B7JSDB/crestani_sperber_2010_experience_report.pdf:application/pdf}
}

@article{ruiz_tilc:_2009,
	title = {{TILC}: {The} {Interactive} {Lambda}-{Calculus} {Tracer}},
	volume = {248},
	issn = {15710661},
	shorttitle = {{TILC}},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1571066109002904},
	doi = {10.1016/j.entcs.2009.07.067},
	language = {en},
	urldate = {2015-08-05},
	journal = {Electronic Notes in Theoretical Computer Science},
	author = {Ruiz, David and Villaret, Mateu},
	month = aug,
	year = {2009},
	pages = {173--183},
	file = {ruiz_villaret_2009_tilc.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/IM73QURT/ruiz_villaret_2009_tilc.pdf:application/pdf}
}

@article{spohrer_novice_1986,
	title = {Novice {Mistakes}: {Are} the {Folk} {Wisdoms} {Correct}?},
	volume = {29},
	issn = {0001-0782},
	shorttitle = {Novice {Mistakes}},
	url = {http://doi.acm.org/10.1145/6138.6145},
	doi = {10.1145/6138.6145},
	abstract = {An evaluation of two folk wisdoms serves to elucidate the underlying or "deep-structure" reasons for novice errors.},
	number = {7},
	urldate = {2015-09-24},
	journal = {Commun. ACM},
	author = {Spohrer, James C. and Soloway, Elliot},
	month = jul,
	year = {1986},
	pages = {624--632},
	file = {spohrer_soloway_1986_novice_mistakes.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/QPMHR48B/spohrer_soloway_1986_novice_mistakes.pdf:application/pdf}
}

@article{tirronen_understanding_2015,
	title = {Understanding beginners' mistakes with {Haskell}},
	volume = {25},
	issn = {1469-7653},
	url = {http://journals.cambridge.org/article_S0956796815000179},
	doi = {10.1017/S0956796815000179},
	abstract = {This article presents an overview of student difficulties in an introductory functional programming (FP) course taught in Haskell. The motivation for this study stems from our belief that many student difficulties can be alleviated by understanding the underlying causes of errors and by modifying the educational approach and, possibly, the teaching language accordingly. We analyze students' exercise submissions and categorize student errors according to compiler error messages and then manually according to the observed underlying cause. Our study complements earlier studies on the topic by applying computer and manual analysis while focusing on providing descriptive statistics of difficulties specific to FP languages. We conclude that the majority of student errors, regardless of cause, are reported by three different compiler error messages that are not well understood by students. In addition, syntactic features, such as precedence, the syntax of function application, and deeply nested statements, cause difficulties throughout the course.},
	urldate = {2015-10-22},
	journal = {Journal of Functional Programming},
	author = {Tirronen, Ville and Uusi-Mäkelä, Samuel and Isomöttönen, Ville},
	year = {2015},
	file = {Cambridge Journals Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/BVI4NMAC/displayAbstract.html:text/html;tirronen_et_al_2015_understanding_beginners'_mistakes_with_haskell.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/I4SDJCQJ/tirronen_et_al_2015_understanding_beginners'_mistakes_with_haskell.pdf:application/pdf}
}

@incollection{gast_explaining_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Explaining {ML} {Type} {Errors} by {Data} {Flows}},
	copyright = {©2005 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-26094-3 978-3-540-32038-8},
	url = {http://link.springer.com/chapter/10.1007/11431664_5},
	abstract = {We present a novel approach to explaining ML type errors: Since the type system inhibits data flows that would abort the program at run-time, our type checker identifies as explanations those data flows that violate the typing rules. It also detects the notorious backflows, which are artifacts of unification, and warns the user about the possibly unexpected typing. The generated explanations comprise a detailed textual description and an arrow overlay to the source code, in which each arrowrepresents one data flow. The description refers only to elementary facts about program evaluation, not to the type checking process itself. The method integrates well with unification-based type checking: Type-correct programs incur a modest overhead compared to normal type checking. If a type error occurs, a simple depth-first graph traversal yields the explanation. A proof-of-concept implementation is available.},
	language = {en},
	number = {3474},
	urldate = {2015-05-27},
	booktitle = {Implementation and {Application} of {Functional} {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Gast, Holger},
	editor = {Grelck, Clemens and Huch, Frank and Michaelson, Greg J. and Trinder, Phil},
	year = {2005},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques},
	pages = {72--89},
	file = {gast_2005_explaining_ml_type_errors_by_data_flows.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/NIV2GECF/gast_2005_explaining_ml_type_errors_by_data_flows.pdf:application/pdf}
}

@inproceedings{naylor_finding_2007,
	series = {{SCAM} '07},
	title = {Finding {Inputs} that {Reach} a {Target} {Expression}},
	doi = {10.1109/SCAM.2007.30},
	abstract = {We present an automated program analysis, called Reach, to compute program inputs that cause evaluation of explicitly-marked target expressions. Reach has a range of applications including property refutation, assertion breaking, program crashing, program covering, program understanding, and the development of customised data generators. Reach is based on lazy narrowing, a symbolic evaluation strategy from functional-logic programming. We use Reach to analyse a range of programs, and find it to be a useful tool with clear performance benefits over a method based on exhaustive input generation. We also explore different methods for bounding the search space, the selective use of breadth-first search to find the first solution quickly, and techniques to avoid evaluation that is unnecessary to reach a target.},
	booktitle = {Seventh {IEEE} {International} {Working} {Conference} on {Source} {Code} {Analysis} and {Manipulation}, 2007. {SCAM} 2007},
	author = {Naylor, M. and Runciman, Colin},
	month = sep,
	year = {2007},
	keywords = {\_tablet, Application software, assertion breaking, automatic testing, breadth-first search, Computer crashes, Computer science, Concrete, customised data generator, explicitly-marked target expression, functional-logic programming, functional programming, lazy narrowing, logic programming, Performance analysis, Power generation, program covering, program crashing, program diagnostics, Program processors, program testing, program understanding, property refutation, Reach automated program analysis, research-exam, symbolic evaluation strategy, symbol manipulation, Target recognition},
	pages = {133--142},
	file = {naylor_runciman_2007_finding_inputs_that_reach_a_target_expression.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/DNE432GG/naylor_runciman_2007_finding_inputs_that_reach_a_target_expression.pdf:application/pdf}
}

@inproceedings{pavlinovic_practical_2015,
	address = {New York, NY, USA},
	series = {{ICFP} 2015},
	title = {Practical {SMT}-based {Type} {Error} {Localization}},
	isbn = {978-1-4503-3669-7},
	url = {http://doi.acm.org/10.1145/2784731.2784765},
	doi = {10.1145/2784731.2784765},
	abstract = {Compilers for statically typed functional programming languages are notorious for generating confusing type error messages. When the compiler detects a type error, it typically reports the program location where the type checking failed as the source of the error. Since other error sources are not even considered, the actual root cause is often missed. A more adequate approach is to consider all possible error sources and report the most useful one subject to some usefulness criterion. In our previous work, we showed that this approach can be formulated as an optimization problem related to satisfiability modulo theories (SMT). This formulation cleanly separates the heuristic nature of usefulness criteria from the underlying search problem. Unfortunately, algorithms that search for an optimal error source cannot directly use principal types which are crucial for dealing with the exponential-time complexity of the decision problem of polymorphic type checking. In this paper, we present a new algorithm that efficiently finds an optimal error source in a given ill-typed program. Our algorithm uses an improved SMT encoding to cope with the high complexity of polymorphic typing by iteratively expanding the typing constraints from which principal types are derived. The algorithm preserves the clean separation between the heuristics and the actual search. We have implemented our algorithm for OCaml. In our experimental evaluation, we found that the algorithm reduces the running times for optimal type error localization from minutes to seconds and scales better than previous localization algorithms.},
	urldate = {2015-09-03},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Pavlinovic, Zvonimir and King, Tim and Wies, Thomas},
	year = {2015},
	keywords = {Polymorphic Types, satisfiability modulo theories, Type Error Localization},
	pages = {412--423},
	file = {pavlinovic_et_al_2015_practical_smt-based_type_error_localization.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/STX7CR34/pavlinovic_et_al_2015_practical_smt-based_type_error_localization.pdf:application/pdf}
}

@inproceedings{zhang_toward_2014,
	address = {New York, NY, USA},
	series = {{POPL} '14},
	title = {Toward {General} {Diagnosis} of {Static} {Errors}},
	isbn = {978-1-4503-2544-8},
        doi = {10.1145/2535838.2535870},
	abstract = {We introduce a general way to locate programmer mistakes that are detected by static analyses such as type checking. The program analysis is expressed in a constraint language in which mistakes result in unsatisfiable constraints. Given an unsatisfiable system of constraints, both satisfiable and unsatisfiable constraints are analyzed, to identify the program expressions most likely to be the cause of unsatisfiability. The likelihood of different error explanations is evaluated under the assumption that the programmer's code is mostly correct, so the simplest explanations are chosen, following Bayesian principles. For analyses that rely on programmer-stated assumptions, the diagnosis also identifies assumptions likely to have been omitted. The new error diagnosis approach has been implemented for two very different program analyses: type inference in OCaml and information flow checking in Jif. The effectiveness of the approach is evaluated using previously collected programs containing errors. The results show that when compared to existing compilers and other tools, the general technique identifies the location of programmer errors significantly more accurately.},
	urldate = {2015-01-21},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Zhang, Danfeng and Myers, Andrew C.},
	year = {2014},
	keywords = {error diagnosis, information flow, static program analysis, type inference},
	pages = {569--581},
	file = {zhang_myers_2014_toward_general_diagnosis_of_static_errors.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/8WP6HDZC/zhang_myers_2014_toward_general_diagnosis_of_static_errors.pdf:application/pdf}
}

@article{pierce_local_2000,
	title = {Local {Type} {Inference}},
	volume = {22},
	issn = {0164-0925},
	url = {http://doi.acm.org/10.1145/345099.345100},
	doi = {10.1145/345099.345100},
	abstract = {We study two partial type inference methods for a language combining subtyping and impredicative polymorphism. Both methods are local in the sense that missing annotations are recovered using only information from adjacent nodes in the syntax tree, without long-distance constraints such as unification variables. One method infers type arguments in polymorphic applications using a local constraint solver. The other infers annotations on bound variables in function abstractions by propagating type constraints downward from enclosing application nodes. We motivate our design choices by a statistical analysis of the uses of type inference in a sizable body of existing ML code.},
	number = {1},
	urldate = {2015-05-27},
	journal = {ACM Trans. Program. Lang. Syst.},
	author = {Pierce, Benjamin C. and Turner, David N.},
	month = jan,
	year = {2000},
	keywords = {polymorphism, subtyping, type inference},
	pages = {1--44},
	file = {pierce_turner_2000_local_type_inference.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/3PA6HMRX/pierce_turner_2000_local_type_inference.pdf:application/pdf}
}

@inproceedings{plociniczak_improving_2014,
	title = {Improving {Human}-{Compiler} {Interaction} {Through} {Customizable} {Type} {Feedback}},
	booktitle = {{SPLASH}},
	author = {Plociniczak, Hubert and Miller, Heather and Odersky, Martin},
	year = {2014},
	keywords = {\_tablet},
	file = {plociniczak_et_al_2014_improving_human-compiler_interaction_through_customizable_type_feedback.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/QIVUNM27/plociniczak_et_al_2014_improving_human-compiler_interaction_through_customizable_type_feedback.pdf:application/pdf}
}

@inproceedings{nienaltowski_compiler_2008,
	address = {New York, NY, USA},
	series = {{SIGCSE} '08},
	title = {Compiler {Error} {Messages}: {What} {Can} {Help} {Novices}?},
	isbn = {978-1-59593-799-5},
	shorttitle = {Compiler {Error} {Messages}},
	url = {http://doi.acm.org/10.1145/1352135.1352192},
	doi = {10.1145/1352135.1352192},
	abstract = {Novices find it difficult to understand and use compiler error messages. It is useful to refine this observation and study the effect of different message styles on how well and quickly students identify errors in programs. For example, does an increased level of detail simplify the understanding of errors and their correction? We analyzed messages produced by a number of compilers for five programming languages, and grouped them into three style categories from their level of detail and presentation format, and correlated the level of experience and error type with performance and speed of response. The study involved two groups of students taking an introductory programming course at two different institutions; they used messages in these three styles to debug erroneous code. The results indicate that more detailed messages do not necessarily simplify the understanding of errors but that it matters more where information is placed and how it is structured.},
	urldate = {2015-09-24},
	booktitle = {Proceedings of the 39th {SIGCSE} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Nienaltowski, Marie-Hélène and Pedroni, Michela and Meyer, Bertrand},
	year = {2008},
	keywords = {compiler error messages, novice programmers},
	pages = {168--172},
	file = {nienaltowski_et_al_2008_compiler_error_messages.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/KTFF3NS8/nienaltowski_et_al_2008_compiler_error_messages.pdf:application/pdf}
}

@inproceedings{jadud_methods_2006,
	address = {New York, NY, USA},
	series = {{ICER} '06},
	title = {Methods and {Tools} for {Exploring} {Novice} {Compilation} {Behaviour}},
	isbn = {978-1-59593-494-9},
	url = {http://doi.acm.org/10.1145/1151588.1151600},
	doi = {10.1145/1151588.1151600},
	abstract = {Our research explores what we call compilation behaviour: the programming behaviour a student engages in while repeatedly editing and compiling their programs. This edit-compile cycle often represents students' attempts to make their programs syntactically, as opposed to semantically, correct. Over the course of two years, we have observed first-year university students learning to program in Java, collecting and studying thousands of snapshots of their programs from one compilation to the next. At the University of Kent, students are introduced to programming in an objects-first style using BlueJ, an environment intended for use by novice programmers.},
	urldate = {2015-09-24},
	booktitle = {Proceedings of the {Second} {International} {Workshop} on {Computing} {Education} {Research}},
	publisher = {ACM},
	author = {Jadud, Matthew C.},
	year = {2006},
	keywords = {behavior, BlueJ, compilation, compiler, Java, novice},
	pages = {73--84},
	file = {jadud_2006_methods_and_tools_for_exploring_novice_compilation_behaviour.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/9ZVE24B5/jadud_2006_methods_and_tools_for_exploring_novice_compilation_behaviour.pdf:application/pdf}
}

@article{olmer_evaluating_2014,
	title = {Evaluating {Haskell} expressions in a tutoring environment},
	volume = {170},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1412.4879v1},
	doi = {10.4204/EPTCS.170.4},
	language = {en},
	urldate = {2015-09-25},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Olmer, Tim and Heeren, Bastiaan and Jeuring, Johan},
	month = dec,
	year = {2014},
	keywords = {Computer Science - Computers and Society, Computer Science - Programming Languages},
	pages = {50--66},
	file = {arXiv.org Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/6KC5EIXN/1412.html:text/html;olmer_et_al_2014_evaluating_haskell_expressions_in_a_tutoring_environment.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/ZVQ5V4AS/olmer_et_al_2014_evaluating_haskell_expressions_in_a_tutoring_environment.pdf:application/pdf;olmer_et_al_2014_evaluating_haskell_expressions_in_a_tutoring_environment.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/745CU7AD/olmer_et_al_2014_evaluating_haskell_expressions_in_a_tutoring_environment.pdf:application/pdf}
}

@inproceedings{pavlinovic_finding_2014,
	address = {New York, NY, USA},
	series = {{OOPSLA} '14},
	title = {Finding {Minimum} {Type} {Error} {Sources}},
	isbn = {978-1-4503-2585-1},
        doi = {10.1145/2660193.2660230},
	abstract = {Automatic type inference is a popular feature of functional programming languages. If a program cannot be typed, the compiler typically reports a single program location in its error message. This location is the point where the type inference failed, but not necessarily the actual source of the error. Other potential error sources are not even considered. Hence, the compiler often misses the true error source, which increases debugging time for the programmer. In this paper, we present a general framework for automatic localization of type errors. Our algorithm finds all minimum error sources, where the exact definition of minimum is given in terms of a compiler-specific ranking criterion. Compilers can use minimum error sources to produce more meaningful error reports, and for automatic error correction. Our approach works by reducing the search for minimum error sources to an optimization problem that we formulate in terms of weighted maximum satisfiability modulo theories (MaxSMT). The reduction to weighted MaxSMT allows us to build on SMT solvers to support rich type systems and at the same time abstract from the concrete criterion that is used for ranking the error sources. We have implemented an instance of our framework targeted at Hindley-Milner type systems and evaluated it on existing OCaml benchmarks for type error localization. Our evaluation shows that our approach has the potential to significantly improve the quality of type error reports produced by state of the art compilers.},
	urldate = {2015-04-27},
	booktitle = {Proceedings of the 2014 {ACM} {International} {Conference} on {Object} {Oriented} {Programming} {Systems} {Languages} \&\#38; {Applications}},
	publisher = {ACM},
	author = {Pavlinovic, Zvonimir and King, Tim and Wies, Thomas},
	year = {2014},
	keywords = {diagnostics, satisfiability modulo theories, type errors},
	pages = {525--542},
	file = {pavlinovic_et_al_2014_finding_minimum_type_error_sources.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/M8ICSCQE/pavlinovic_et_al_2014_finding_minimum_type_error_sources.pdf:application/pdf}
}

@incollection{okeefe_type_1992,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Type inference for partial types is decidable},
	copyright = {©1992 Springer-Verlag},
	isbn = {978-3-540-55253-6 978-3-540-46803-5},
	url = {http://link.springer.com/chapter/10.1007/3-540-55253-7_24},
	abstract = {The type inference problem for partial types, introduced by Thatte [15], is the problem of deducing types under a subtype relation with a largest element Ω and closed under the usual antimonotonic rule for function types. We show that this problem is decidable by reducing it to a satisfiability problem for type expressions over this partial order and giving an algorithm for the satisfiability problem. The satisfiability problem is harder than the one conventionally given because comparable types may have radically different shapes.},
	language = {en},
	number = {582},
	urldate = {2015-05-27},
	booktitle = {{ESOP} '92},
	publisher = {Springer Berlin Heidelberg},
	author = {O'Keefe, Patrick M. and Wand, Mitchell},
	editor = {Krieg-Brückner, Bernd},
	year = {1992},
	keywords = {Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Software Engineering},
	pages = {408--417},
	file = {o'keefe_wand_1992_type_inference_for_partial_types_is_decidable.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/6G7TESNE/o'keefe_wand_1992_type_inference_for_partial_types_is_decidable.pdf:application/pdf}
}

@inproceedings{stuckey_improving_2004,
	address = {New York, NY, USA},
	series = {Haskell '04},
	title = {Improving {Type} {Error} {Diagnosis}},
	isbn = {1-58113-850-4},
	url = {http://doi.acm.org/10.1145/1017472.1017486},
	doi = {10.1145/1017472.1017486},
	abstract = {We present a number of methods for providing improved type error reports in the Haskell and Chameleon programming languages. We build upon our previous work [19] where we first introduced the idea of discovering type errors by translating the typing problem into a constraint problem and looking for minimal unsatisfiable subsets of constraints. This allowed us to find precise sets of program locations which are in conflict with each other. Here we extend this approach by extracting additional useful information from these minimal unsatisfiable sets. This allows us to report errors as conflicts amongst a number of possible, candidate types. The advantage of our approach is that it offers implementors the flexibility to employ heuristics to select where, amongst all the locations involved, an error should be reported. In addition, we present methods for providing improved subsumption and ambiguity error reporting.},
	urldate = {2015-05-27},
	booktitle = {Proceedings of the 2004 {ACM} {SIGPLAN} {Workshop} on {Haskell}},
	publisher = {ACM},
	author = {Stuckey, Peter J. and Sulzmann, Martin and Wazny, Jeremy},
	year = {2004},
	keywords = {constraints, Hindley/Milner, overloading, type classes, type debugging, type inference},
	pages = {80--91},
	file = {stuckey_et_al_2004_improving_type_error_diagnosis.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/3BBHE74E/stuckey_et_al_2004_improving_type_error_diagnosis.pdf:application/pdf}
}

@incollection{claessen_testing_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Testing and {Tracing} {Lazy} {Functional} {Programs} {Using} {QuickCheck} and {Hat}},
	copyright = {©2003 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-40132-2 978-3-540-44833-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-44833-4_3},
	language = {en},
	number = {2638},
	urldate = {2015-09-25},
	booktitle = {Advanced {Functional} {Programming}},
	publisher = {Springer Berlin Heidelberg},
	author = {Claessen, Koen and Runciman, Colin and Chitil, Olaf and Hughes, John and Wallace, Malcolm},
	editor = {Jeuring, Johan and Jones, Simon L. Peyton},
	year = {2003},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {59--99},
	file = {claessen_et_al_2003_testing_and_tracing_lazy_functional_programs_using_quickcheck_and_hat.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/6ZPW5RXB/claessen_et_al_2003_testing_and_tracing_lazy_functional_programs_using_quickcheck_and_hat.pdf:application/pdf;claessen_et_al_2003_testing_and_tracing_lazy_functional_programs_using_quickcheck_and_hat.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/QBUTKGPF/claessen_et_al_2003_testing_and_tracing_lazy_functional_programs_using_quickcheck_and_hat.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/JPAKV5ZU/10.html:text/html}
}

@inproceedings{pacheco_feedback-directed_2007,
	title = {Feedback-{Directed} {Random} {Test} {Generation}},
	doi = {10.1109/ICSE.2007.37},
	abstract = {We present a technique that improves random test generation by incorporating feedback obtained from executing test inputs as they are created. Our technique builds inputs incrementally by randomly selecting a method call to apply and finding arguments from among previously-constructed inputs. As soon as an input is built, it is executed and checked against a set of contracts and filters. The result of the execution determines whether the input is redundant, illegal, contract-violating, or useful for generating more inputs. The technique outputs a test suite consisting of unit tests for the classes under test. Passing tests can be used to ensure that code contracts are preserved across program changes; failing tests (that violate one or more contract) point to potential errors that should be corrected. Our experimental results indicate that feedback-directed random test generation can outperform systematic and undirected random test generation, in terms of coverage and error detection. On four small but nontrivial data structures (used previously in the literature), our technique achieves higher or equal block and predicate coverage than model checking (with and without abstraction) and undirected random generation. On 14 large, widely-used libraries (comprising 780KLOC), feedback-directed random test generation finds many previously-unknown errors, not found by either model checking or undirected random generation.},
	booktitle = {29th {International} {Conference} on {Software} {Engineering}, 2007. {ICSE} 2007},
	author = {Pacheco, C. and Lahiri, S.K. and Ernst, M.D. and Ball, T.},
	month = may,
	year = {2007},
	keywords = {Contracts, Error correction codes, error detection, failing tests, Feedback, feedback-directed random test generation, Filters, Law, Legal factors, Object oriented modeling, Open source software, passing tests, program testing, software testing, System testing},
	pages = {75--84},
	file = {pacheco_et_al_2007_feedback-directed_random_test_generation.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/5B9A7FW2/pacheco_et_al_2007_feedback-directed_random_test_generation.pdf:application/pdf}
}

@inproceedings{neubauer_discriminative_2003,
	address = {New York, NY, USA},
	series = {{ICFP} '03},
	title = {Discriminative {Sum} {Types} {Locate} the {Source} of {Type} {Errors}},
	isbn = {1-58113-756-7},
        doi = {10.1145/944705.944708},
	abstract = {We propose a type system for locating the source of type errors in an applied lambda calculus with ML-style polymorphism. The system is based on discriminative sum types---known from work on soft typing---with annotation subtyping and recursive types. This way, type clashes can be registered in the type for later reporting. The annotations track the potential producers and consumers for each value so that clashes can be traced to their cause.Every term is typeable in our system and type inference is decidable. A type derivation in our system describes all type errors present in the program, so that a principal derivation yields a principal description of all type errors present. Error messages are derived from completed type derivations. Thus, error messages are independent of the particular algorithm used for type inference, provided it constructs such a derivation.},
	urldate = {2015-05-27},
	booktitle = {Proceedings of the {Eighth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Neubauer, Matthias and Thiemann, Peter},
	year = {2003},
	keywords = {polymorphism, type errors, type inference},
	pages = {15--26},
	file = {neubauer_thiemann_2003_discriminative_sum_types_locate_the_source_of_type_errors.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/DF55DR6U/neubauer_thiemann_2003_discriminative_sum_types_locate_the_source_of_type_errors.pdf:application/pdf}
}

@inproceedings{lindahl_practical_2006,
	address = {New York, NY, USA},
	series = {{PPDP} '06},
	title = {Practical {Type} {Inference} {Based} on {Success} {Typings}},
	isbn = {1-59593-388-3},
	url = {http://doi.acm.org/10.1145/1140335.1140356},
	doi = {10.1145/1140335.1140356},
	abstract = {In languages where the compiler performs no static type checks, many programs never go wrong, but the intended use of functions and component interfaces is often undocumented or appears only in the form of comments which cannot always be trusted. This often makes program maintenance problematic. We show that it is possible to reconstruct a significant portion of the type information which is implicit in a program, automatically annotate function interfaces, and detect definite type clashes without fundamental changes to the philosophy of the language or imposing a type system which unnecessarily rejects perfectly reasonable programs. To do so, we introduce the notion of success typings of functions. Unlike most static type systems, success typings incorporate subtyping and never disallow a use of a function that will not result in a type clash during runtime. Unlike most soft typing systems that have previously been proposed, success typings allow for compositional, bottom-up type inference which appears to scale well in practice. Moreover, by taking control-flow into account and exploiting properties of the language such as its module system, success typings can be refined and become accurate and precise We demonstrate the power and practicality of the approach by applying it to Erlang. We report on our experiences from employing the type inference algorithm, without any guidance, on programs of significant size},
	urldate = {2015-05-27},
	booktitle = {Proceedings of the 8th {ACM} {SIGPLAN} {International} {Conference} on {Principles} and {Practice} of {Declarative} {Programming}},
	publisher = {ACM},
	author = {Lindahl, Tobias and Sagonas, Konstantinos},
	year = {2006},
	keywords = {constraint-based type inference, Erlang, subtyping, success typings},
	pages = {167--178},
	file = {lindahl_sagonas_2006_practical_type_inference_based_on_success_typings.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/KAMINNVP/lindahl_sagonas_2006_practical_type_inference_based_on_success_typings.pdf:application/pdf}
}

@incollection{sestoft_demonstrating_2002,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Demonstrating {Lambda} {Calculus} {Reduction}},
	copyright = {©2002 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-00326-7 978-3-540-36377-4},
	url = {http://link.springer.com/chapter/10.1007/3-540-36377-7_19},
	language = {en},
	number = {2566},
	urldate = {2015-09-25},
	booktitle = {The {Essence} of {Computation}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sestoft, Peter},
	editor = {Mogensen, Torben Æ and Schmidt, David A. and Sudborough, I. Hal},
	year = {2002},
	keywords = {Computation by Abstract Devices, Logics and Meanings of Programs, Software Engineering},
	pages = {420--435},
	file = {sestoft_2002_demonstrating_lambda_calculus_reduction.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/GNMATTT3/sestoft_2002_demonstrating_lambda_calculus_reduction.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/3DV78B3S/10.html:text/html}
}

@article{chambers_function_2012,
	title = {The {Function}, and {Dysfunction}, of {Information} {Sources} in {Learning} {Functional} {Programming}},
	volume = {28},
	issn = {1937-4771},
	url = {http://dl.acm.org/citation.cfm?id=2379703.2379745},
	abstract = {Programmers experienced in using imperative languages can increasingly benefit from also knowing how to use functional languages. However, even if programmers have already mastered general programming constructs such as types and recursion, actually expressing these in a functional language can be challenging. In this paper, we present an observational study investigating what information sources imperative programmers use when they encounter these problems, as well as how well different information sources enable them to overcome problems. By highlighting the central role that external information sources play as students learn functional programming, our results reveal opportunities for more effectively supporting the learning process.},
	number = {1},
	urldate = {2015-10-22},
	journal = {J. Comput. Sci. Coll.},
	author = {Chambers, Christopher and Chen, Sheng and Le, Duc and Scaffidi, Christopher},
	month = oct,
	year = {2012},
	pages = {220--226},
	file = {chambers_et_al_2012_the_function,_and_dysfunction,_of_information_sources_in_learning_functional.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/QQDAFTBV/chambers_et_al_2012_the_function,_and_dysfunction,_of_information_sources_in_learning_functional.pdf:application/pdf}
}

@inproceedings{wright_practical_1994,
	address = {New York, NY, USA},
	series = {{LFP} '94},
	title = {A {Practical} {Soft} {Type} {System} for {Scheme}},
	isbn = {0-89791-643-3},
	url = {http://doi.acm.org/10.1145/182409.182485},
	doi = {10.1145/182409.182485},
	abstract = {Soft typing is a generalization of static type checking that accommodates both dynamic typing and static typing in one framework. A soft type checker infers types for identifiers and inserts explicit run-time checks to transform untypable programs into typable form. Soft Scheme is a practical soft type system for R4RS Scheme. The type checker uses a representation for types that is expressive, easy to interpret, and supports efficient type inference. Soft Scheme supports all of R4RS Scheme, including uncurried procedures of fixed and variable arity, assignment, and continuations.},
	urldate = {2015-05-27},
	booktitle = {Proceedings of the 1994 {ACM} {Conference} on {LISP} and {Functional} {Programming}},
	publisher = {ACM},
	author = {Wright, Andrew K. and Cartwright, Robert},
	year = {1994},
	pages = {250--262},
	file = {wright_cartwright_1994_a_practical_soft_type_system_for_scheme.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/MD6GEKG3/wright_cartwright_1994_a_practical_soft_type_system_for_scheme.pdf:application/pdf}
}

@inproceedings{chen_counter-factual_2014,
	address = {New York, NY, USA},
	series = {{POPL} '14},
	title = {Counter-factual {Typing} for {Debugging} {Type} {Errors}},
	isbn = {978-1-4503-2544-8},
        doi = {10.1145/2535838.2535863},
	abstract = {Changing a program in response to a type error plays an important part in modern software development. However, the generation of good type error messages remains a problem for highly expressive type systems. Existing approaches often suffer from a lack of precision in locating errors and proposing remedies. Specifically, they either fail to locate the source of the type error consistently, or they report too many potential error locations. Moreover, the change suggestions offered are often incorrect. This makes the debugging process tedious and ineffective. We present an approach to the problem of type debugging that is based on generating and filtering a comprehensive set of type-change suggestions. Specifically, we generate all (program-structure-preserving) type changes that can possibly fix the type error. These suggestions will be ranked and presented to the programmer in an iterative fashion. In some cases we also produce suggestions to change the program. In most situations, this strategy delivers the correct change suggestions quickly, and at the same time never misses any rare suggestions. The computation of the potentially huge set of type-change suggestions is efficient since it is based on a variational type inference algorithm that type checks a program with variations only once, efficiently reusing type information for shared parts. We have evaluated our method and compared it with previous approaches. Based on a large set of examples drawn from the literature, we have found that our method outperforms other approaches and provides a viable alternative.},
	urldate = {2015-05-26},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Chen, Sheng and Erwig, Martin},
	year = {2014},
	keywords = {change suggestions, choice types, error localization, type-error debugging, type error messages, type inference},
	pages = {583--594},
	file = {chen_erwig_2014_counter-factual_typing_for_debugging_type_errors.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/UGFAND8T/chen_erwig_2014_counter-factual_typing_for_debugging_type_errors.pdf:application/pdf}
}

@inproceedings{gomard_partial_1990,
	address = {New York, NY, USA},
	series = {{LFP} '90},
	title = {Partial {Type} {Inference} for {Untyped} {Functional} {Programs}},
	isbn = {0-89791-368-X},
	url = {http://doi.acm.org/10.1145/91556.91672},
	doi = {10.1145/91556.91672},
	abstract = {This extended abstract describes a way of inferring as much type information as possible about programs written in an untyped programming language. We present an algorithm that underlines the untypable parts of a program and assigns types to the rest. The algorithm is derived in a very simple manner from the well-known algorithm W of Damas \& Milner [Damas and Milner 1982].
Our algorithm provides us with an easy solution to the problem of doing binding time analysis of the untyped higher order lambda calculus, and thereby of the wide range of programming languages based upon the lambda calculus. The techniques can also be used to eliminate superfluous runtime type checking in untyped functional languages, to produce better error messages from type analyzers for strongly typed languages, and to analyze feasibility of arity raising.},
	urldate = {2015-05-27},
	booktitle = {Proceedings of the 1990 {ACM} {Conference} on {LISP} and {Functional} {Programming}},
	publisher = {ACM},
	author = {Gomard, Carsten K.},
	year = {1990},
	pages = {282--287},
	file = {gomard_1990_partial_type_inference_for_untyped_functional_programs.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/W3EIII3E/gomard_1990_partial_type_inference_for_untyped_functional_programs.pdf:application/pdf}
}

@incollection{chen_guided_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Guided {Type} {Debugging}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07150-3 978-3-319-07151-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07151-0_3},
	abstract = {We present guided type debugging as a new approach to quickly and reliably remove type errors from functional programs. The method works by generating type-change suggestions that satisfy type specifications that are elicited from programmers during the debugging process. A key innovation is the incorporation of target types into the type error debugging process. Whereas previous approaches have aimed exclusively at the removal of type errors and disregarded the resulting types, guided type debugging exploits user feedback about result types to achieve better type-change suggestions. Our method can also identify and remove errors in type annotations, which has been a problem for previous approaches. To efficiently implement our approach, we systematically generate all potential type changes and arrange them in a lattice structure that can be efficiently traversed when guided by target types that are provided by programmers.},
	language = {en},
	number = {8475},
	urldate = {2015-10-27},
	booktitle = {Functional and {Logic} {Programming}},
	publisher = {Springer International Publishing},
	author = {Chen, Sheng and Erwig, Martin},
	editor = {Codish, Michael and Sumii, Eijiro},
	month = jun,
	year = {2014},
	note = {DOI: 10.1007/978-3-319-07151-0\_3},
	keywords = {Artificial Intelligence (incl. Robotics), change suggestions, choice types, error localization, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering, type debugging, type error messages, type inference},
	pages = {35--51},
	file = {chen_erwig_2014_guided_type_debugging.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/T3TH9JQC/chen_erwig_2014_guided_type_debugging.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/6VM4MKSE/10.html:text/html}
}

@inproceedings{vytiniotis_equality_2012,
	address = {New York, NY, USA},
	series = {{ICFP} '12},
	title = {Equality {Proofs} and {Deferred} {Type} {Errors}: {A} {Compiler} {Pearl}},
	isbn = {978-1-4503-1054-3},
	shorttitle = {Equality {Proofs} and {Deferred} {Type} {Errors}},
        doi = {10.1145/2364527.2364554},
	abstract = {The Glasgow Haskell Compiler is an optimizing compiler that expresses and manipulates first-class equality proofs in its intermediate language. We describe a simple, elegant technique that exploits these equality proofs to support deferred type errors. The technique requires us to treat equality proofs as possibly-divergent terms; we show how to do so without losing either soundness or the zero-overhead cost model that the programmer expects.},
	urldate = {2015-10-27},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Vytiniotis, Dimitrios and Peyton Jones, Simon and Magalhães, José Pedro},
	year = {2012},
	keywords = {deferred type errors, system fc, type equalities},
	pages = {341--352},
	file = {vytiniotis_et_al_2012_equality_proofs_and_deferred_type_errors.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/38JQ79NW/vytiniotis_et_al_2012_equality_proofs_and_deferred_type_errors.pdf:application/pdf}
}

@article{joosten_teaching_1993,
	title = {Teaching functional programming to first-year students},
	volume = {3},
	issn = {1469-7653},
	url = {http://journals.cambridge.org/article_S0956796800000599},
	doi = {10.1017/S0956796800000599},
	abstract = {In the period 1986–1991, experiments have been carried out with an introductory course in computer programming, based on functional programming. Due to thorough educational design and evaluation, a successful course has been developed. This has led to a revision of the computer programming education in the first year of the computer science curriculum at the University of Twente.This article describes the approach, the aim of the computer programming course, the outline and subject matter of the course, and the evaluation. Educational research has been done to assess the quality of the course.},
	number = {01},
	urldate = {2015-03-04},
	journal = {Journal of Functional Programming},
	author = {Joosten, Stef and Van Den Berg, Klaas and Van Der Hoeven, Gerrit},
	month = jan,
	year = {1993},
	keywords = {education, functional programming},
	pages = {49--65},
	file = {joosten_et_al_1993_teaching_functional_programming_to_first-year_students.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/KESEGIV9/joosten_et_al_1993_teaching_functional_programming_to_first-year_students.pdf:application/pdf}
}

@incollection{thatte_type_1988,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Type inference with partial types},
	copyright = {©1988 Springer-Verlag},
	isbn = {978-3-540-19488-0 978-3-540-39291-0},
	url = {http://link.springer.com/chapter/10.1007/3-540-19488-6_146},
	abstract = {This paper introduces a new form of type expressions which represent partial type information. These expressions are meant to capture the type information statically derivable from heterogeneous objects. The new monotypes form a lattice of subtypes and require type inference based on inclusion constraints. We discuss the existence and form of principle types under this extension and present a semi-decision procedure for the well-typing problem which can be restricted to a form that terminates for most practical programs. The partial type information derivable for heterogeneous entities is not sufficient to guarantee type-correctness for many of their uses. We therefore introduce a notion of statically generated dynamic type checks. Finally, all these elements are pulled together to sketch the derivation of a static system for "plausibility checking" which identifies the applications which may require a dynamic check and catches many type errors.},
	language = {en},
	number = {317},
	urldate = {2015-05-27},
	booktitle = {Automata, {Languages} and {Programming}},
	publisher = {Springer Berlin Heidelberg},
	author = {Thatte, Satish},
	editor = {Lepistö, Timo and Salomaa, Arto},
	year = {1988},
	keywords = {Algorithm Analysis and Problem Complexity, Programming Languages, Compilers, Interpreters, Programming Techniques},
	pages = {615--629},
	file = {thatte_1988_type_inference_with_partial_types.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/62XD2THK/thatte_1988_type_inference_with_partial_types.pdf:application/pdf}
}

@inproceedings{renieris_almost:_1999,
	address = {New York, NY, USA},
	series = {{NPIVM} '99},
	title = {Almost: {Exploring} {Program} {Traces}},
	isbn = {978-1-58113-254-0},
	shorttitle = {Almost},
	url = {http://doi.acm.org/10.1145/331770.331788},
	doi = {10.1145/331770.331788},
	abstract = {We built a tool to visualize and explore program execution traces. Our goal was to help programmers without any prior knowledge of a program, quickly get enough knowledge about its structure so that they can make small to medium changes. In the process, a number of problems were faced and tackled concerning the efficient use of screen space, interaction with multiple concurrent views, and linking of asymmetric views},
	urldate = {2015-10-29},
	booktitle = {Proceedings of the 1999 {Workshop} on {New} {Paradigms} in {Information} {Visualization} and {Manipulation} in {Conjunction} with the {Eighth} {ACM} {Internation} {Conference} on {Information} and {Knowledge} {Management}},
	publisher = {ACM},
	author = {Renieris, Manos and Reiss, Steven P.},
	year = {1999},
	keywords = {connected views, program traces, software visualization, spiral},
	pages = {70--77},
	file = {renieris_reiss_1999_almost.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/8GDP68VU/renieris_reiss_1999_almost.pdf:application/pdf}
}

@inproceedings{guo_online_2013,
	address = {New York, NY, USA},
	series = {{SIGCSE} '13},
	title = {Online {Python} {Tutor}: {Embeddable} {Web}-based {Program} {Visualization} for {Cs} {Education}},
	isbn = {978-1-4503-1868-6},
	shorttitle = {Online {Python} {Tutor}},
	url = {http://doi.acm.org/10.1145/2445196.2445368},
	doi = {10.1145/2445196.2445368},
	abstract = {This paper presents Online Python Tutor, a web-based program visualization tool for Python, which is becoming a popular language for teaching introductory CS courses. Using this tool, teachers and students can write Python programs directly in the web browser (without installing any plugins), step forwards and backwards through execution to view the run-time state of data structures, and share their program visualizations on the web. In the past three years, over 200,000 people have used Online Python Tutor to visualize their programs. In addition, instructors in a dozen universities such as UC Berkeley, MIT, the University of Washington, and the University of Waterloo have used it in their CS1 courses. Finally, Online Python Tutor visualizations have been embedded within three web-based digital Python textbook projects, which collectively attract around 16,000 viewers per month and are being used in at least 25 universities. Online Python Tutor is free and open source software, available at pythontutor.com.},
	urldate = {2015-10-29},
	booktitle = {Proceeding of the 44th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education}},
	publisher = {ACM},
	author = {Guo, Philip J.},
	year = {2013},
	keywords = {CS1, program visualization, python},
	pages = {579--584},
	file = {guo_2013_online_python_tutor.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/3Q3CG6I9/guo_2013_online_python_tutor.pdf:application/pdf}
}

@article{chakravarty_risks_2004,
	title = {The risks and benefits of teaching purely functional programming in first year},
	volume = {14},
	issn = {1469-7653},
	url = {http://journals.cambridge.org/article_S0956796803004805},
	doi = {10.1017/S0956796803004805},
	abstract = {We argue that teaching purely functional programming as such in freshman courses is detrimental to both the curriculum as well as to promoting the paradigm. Instead, we need to focus on the more general aims of teaching elementary techniques of programming and essential concepts of computing. We support this viewpoint with experience gained during several semesters of teaching large first-year classes (up to 600 students) in Haskell. These classes consisted of computer science students as well as students from other disciplines. We have systematically gathered student feedback by conducting surveys after each semester. This article contributes an approach to the use of modern functional languages in first year courses and, based on this, advocates the use of functional languages in this setting.},
	number = {01},
	urldate = {2015-03-04},
	journal = {Journal of Functional Programming},
	author = {Chakravarty, Manuel M. T. and Keller, Gabriele},
	month = jan,
	year = {2004},
	keywords = {education, functional programming},
	pages = {113--123},
	file = {chakravarty_keller_2004_the_risks_and_benefits_of_teaching_purely_functional_programming_in_first_year.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/DZ7XWQV6/chakravarty_keller_2004_the_risks_and_benefits_of_teaching_purely_functional_programming_in_first_year.pdf:application/pdf}
}

@inproceedings{cadar_klee:_2008,
	address = {Berkeley, CA, USA},
	series = {{OSDI}'08},
	title = {{KLEE}: {Unassisted} and {Automatic} {Generation} of {High}-coverage {Tests} for {Complex} {Systems} {Programs}},
	shorttitle = {{KLEE}},
	url = {http://dl.acm.org/citation.cfm?id=1855741.1855756},
	abstract = {We present a new symbolic execution tool, KLEE, capable of automatically generating tests that achieve high coverage on a diverse set of complex and environmentally-intensive programs. We used KLEE to thoroughly check all 89 stand-alone programs in the GNU COREUTILS utility suite, which form the core user-level environment installed on millions of Unix systems, and arguably are the single most heavily tested set of open-source programs in existence. KLEE-generated tests achieve high line coverage -- on average over 90\% per tool (median: over 94\%) -- and significantly beat the coverage of the developers' own hand-written test suite. When we did the same for 75 equivalent tools in the BUSYBOX embedded system suite, results were even better, including 100\% coverage on 31 of them. We also used KLEE as a bug finding tool, applying it to 452 applications (over 430K total lines of code), where it found 56 serious bugs, including three in COREUTILS that had been missed for over 15 years. Finally, we used KLEE to crosscheck purportedly identical BUSYBOX and COREUTILS utilities, finding functional correctness errors and a myriad of inconsistencies.},
	urldate = {2015-01-23},
	booktitle = {Proceedings of the 8th {USENIX} {Conference} on {Operating} {Systems} {Design} and {Implementation}},
	publisher = {USENIX Association},
	author = {Cadar, Cristian and Dunbar, Daniel and Engler, Dawson},
	year = {2008},
	pages = {209--224},
	file = {cadar_et_al_2008_klee.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/4DAJT3BF/cadar_et_al_2008_klee.pdf:application/pdf}
}

@article{thompson_functional_1993,
	title = {Functional programming in education – {Introduction}},
	volume = {3},
	issn = {1469-7653},
	url = {http://journals.cambridge.org/article_S0956796800000563},
	doi = {10.1017/S0956796800000563},
	number = {01},
	urldate = {2015-03-04},
	journal = {Journal of Functional Programming},
	author = {Thompson, Simon and Wadler, Philip},
	month = jan,
	year = {1993},
	keywords = {education, functional programming},
	pages = {3--4},
	file = {thompson_wadler_1993_functional_programming_in_education_–_introduction.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/2986CQIH/thompson_wadler_1993_functional_programming_in_education_–_introduction.pdf:application/pdf}
}

@article{ishii_report_2014,
	title = {Report on a {User} {Test} and {Extension} of a {Type} {Debugger} for {Novice} {Programmers}},
	volume = {170},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1412.4877},
	doi = {10.4204/EPTCS.170.1},
	abstract = {A type debugger interactively detects the expressions that cause type errors. It asks users whether they intend the types of identifiers to be those that the compiler inferred. However, it seems that novice programmers often get in trouble when they think about how to fix type errors by reading the messages given by the type debugger. In this paper, we analyze the user tests of a type debugger and report problems of the current type debugger. We then extend the type debugger to address these problems. Specifically, we introduce expression-specific error messages and language levels. Finally, we show type errors that we think are difficult to explain to novice programmers. The subjects of the user tests were 40 novice students belonging to the department of information science at Ochanomizu University.},
	urldate = {2015-10-29},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Ishii, Yuki and Asai, Kenichi},
	month = dec,
	year = {2014},
	note = {arXiv: 1412.4877},
	keywords = {Computer Science - Programming Languages, Computer Science - Software Engineering, D.2.5},
	pages = {1--18},
	file = {arXiv.org Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/X5JF6EUD/1412.html:text/html;ishii_asai_2014_report_on_a_user_test_and_extension_of_a_type_debugger_for_novice_programmers.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/ZTFTPHZV/ishii_asai_2014_report_on_a_user_test_and_extension_of_a_type_debugger_for_novice_programmers.pdf:application/pdf}
}

@incollection{sparud_complete_1997,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Complete and partial redex trails of functional computations},
	copyright = {©1998 Springer-Verlag},
	isbn = {978-3-540-64849-9 978-3-540-68528-9},
	url = {http://link.springer.com/chapter/10.1007/BFb0055430},
	abstract = {Redex trails are histories of functional computations by graph reduction; their main application is fault-tracing. A prototype implementation of a tracer based on redex trails [8] demonstrated the promise of the technique, but was limited in two respects: (1) trails did not record every reduction, only those constructing a new value; (2) even so computing trails was very expensive, particularly in terms of the memory space they occupied. In this paper, we address both problems: complete redex trails provide a full computational record; partial versions of these trails exclude all but selected details, greatly reducing memory costs. We include results of experiments tracing several applications, including a compiler.},
	language = {en},
	number = {1467},
	urldate = {2015-10-29},
	booktitle = {Implementation of {Functional} {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sparud, Jan and Runciman, Colin},
	editor = {Clack, Chris and Hammond, Kevin and Davie, Tony},
	month = sep,
	year = {1997},
	note = {DOI: 10.1007/BFb0055430},
	keywords = {Logics and Meanings of Programs, Programming Languages, Compilers, Interpreters, Programming Techniques},
	pages = {160--177},
	file = {Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/WXUMCQS3/10.html:text/html;sparud_runciman_1997_complete_and_partial_redex_trails_of_functional_computations.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/E2G9GJ83/sparud_runciman_1997_complete_and_partial_redex_trails_of_functional_computations.pdf:application/pdf}
}

@inproceedings{lindblad_property_2007,
	series = {Trends in {Functional} {Programming}},
	title = {Property {Directed} {Generation} of {First}-{Order} {Test} {Data}},
	volume = {8},
	isbn = {978-1-84150-196-3},
	booktitle = {Proceedings of the {Eighth} {Symposium} on {Trends} in {Functional} {Programming}, {TFP} 2007, {New} {York} {City}, {New} {York}, {USA}, {April} 2-4. 2007},
	publisher = {Intellect},
	author = {Lindblad, Fredrik},
	editor = {Morazán, Marco T.},
	year = {2007},
	keywords = {\_tablet, research-exam},
	pages = {105--123},
	file = {lindblad_2007_property_directed_generation_of_first-order_test_data.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/QJPQ3XB5/lindblad_2007_property_directed_generation_of_first-order_test_data.pdf:application/pdf}
}

@article{kishon_semantics_1995,
	title = {Semantics directed program execution monitoring},
	volume = {5},
	issn = {1469-7653},
	url = {http://journals.cambridge.org/article_S0956796800001465},
	doi = {10.1017/S0956796800001465},
	abstract = {Monitoring semantics is a formal model of program execution which captures ‘monitoring activity’ as found in profilers, tracers, debuggers, etc. Beyond its theoretical interest, this formalism provides a new methodology for implementing a large family of source-level monitoring activities for sequential deterministic programming languages. In this article we explore the use of monitoring semantics in the specification and implementation of a variety of monitors: profilers, tracers, collecting interpreters, and, most importantly, interactive source-level debuggers. Although we consider such monitors only for (both strict and non-strict) functional languages, the methodology extends easily to imperative languages, since it begins with a continuation semantics specification.In addition, using standard partial evaluation techniques as an optimization strategy, we show that the methodology forms a practical basis for building real monitors. Our system can be optimized at two levels of specialization: specializing the interpreter with respect to a monitor specification automatically yields an instrumented interpreter; further specializing this instrumented interpreter with respect to a source program yields an instrumented program, i.e. one in which the extra code to perform monitoring has been automatically embedded into the program.},
	number = {04},
	urldate = {2015-10-29},
	journal = {Journal of Functional Programming},
	author = {Kishon, Amir and Hudak, Paul},
	year = {1995},
	pages = {501--547},
	file = {Cambridge Journals Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/I2JMT7GU/displayAbstract.html:text/html;kishon_hudak_1995_semantics_directed_program_execution_monitoring.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/KAEEKP2K/kishon_hudak_1995_semantics_directed_program_execution_monitoring.pdf:application/pdf}
}

@inproceedings{godefroid_compositional_2007,
	address = {New York, NY, USA},
	series = {{POPL} '07},
	title = {Compositional {Dynamic} {Test} {Generation}},
	isbn = {1-59593-575-4},
	url = {http://doi.acm.org/10.1145/1190216.1190226},
	doi = {10.1145/1190216.1190226},
	abstract = {Dynamic test generation is a form of dynamic program analysis that attempts to compute test inputs to drive a program along a specific program path. Directed Automated Random Testing, or DART for short, blends dynamic test generation with model checking techniques with the goal of systematically executing all feasible program paths of a program while detecting various types of errors using run-time checking tools (like Purify, for instance). Unfortunately, systematically executing all feasible program paths does not scale to large, realistic programs.This paper addresses this major limitation and proposes to perform dynamic test generation compositionally, by adapting known techniques for interprocedural static analysis. Specifically, we introduce a new algorithm, dubbed SMART for Systematic Modular Automated Random Testing, that extends DART by testing functions in isolation, encoding test results as function summaries expressed using input preconditions and output postconditions, and then re-using those summaries when testing higher-level functions. We show that, for a fixed reasoning capability, our compositional approach to dynamic test generation (SMART) is both sound and complete compared to monolithic dynamic test generation (DART). In other words, SMART can perform dynamic test generation compositionally without any reduction in program path coverage. We also show that, given a bound on the maximum number of feasible paths in individual program functions, the number of program executions explored by SMART is linear in that bound, while the number of program executions explored by DART can be exponential in that bound. We present examples of C programs and preliminary experimental results that illustrate and validate empirically these properties.},
	urldate = {2015-01-23},
	booktitle = {Proceedings of the 34th {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Godefroid, Patrice},
	year = {2007},
	keywords = {automatic test generation, compositional program analysis, program verification, scalability, software testing},
	pages = {47--54},
	file = {godefroid_2007_compositional_dynamic_test_generation.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/3V8679H2/godefroid_2007_compositional_dynamic_test_generation.pdf:application/pdf}
}

@inproceedings{chen_error-tolerant_2012,
	address = {New York, NY, USA},
	series = {{ICFP} '12},
	title = {An {Error}-tolerant {Type} {System} for {Variational} {Lambda} {Calculus}},
	isbn = {978-1-4503-1054-3},
	url = {http://doi.acm.org/10.1145/2364527.2364535},
	doi = {10.1145/2364527.2364535},
	abstract = {Conditional compilation and software product line technologies make it possible to generate a huge number of different programs from a single software project. Typing each of these programs individually is usually impossible due to the sheer number of possible variants. Our previous work has addressed this problem with a type system for variational lambda calculus (VLC), an extension of lambda calculus with basic constructs for introducing and organizing variation. Although our type inference algorithm is more efficient than the brute-force strategy of inferring the types of each variant individually, it is less robust since type inference will fail for the entire variational expression if any one variant contains a type error. In this work, we extend our type system to operate on VLC expressions containing type errors. This extension directly supports locating ill-typed variants and the incremental development of variational programs. It also has many subtle implications for the unification of variational types. We show that our extended type system possesses a principal typing property and that the underlying unification problem is unitary. Our unification algorithm computes partial unifiers that lead to result types that (1) contain errors in as few variants as possible and (2) are most general. Finally, we perform an empirical evaluation to determine the overhead of this extension compared to our previous work, to demonstrate the improvements over the brute-force approach, and to explore the effects of various error distributions on the inference process.},
	urldate = {2015-05-26},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Chen, Sheng and Erwig, Martin and Walkingshaw, Eric},
	year = {2012},
	keywords = {error-tolerant type systems, variational lambda calculus, variational type inference, variational types},
	pages = {29--40},
	file = {chen_et_al_2012_an_error-tolerant_type_system_for_variational_lambda_calculus.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/JKZ9ZB7W/chen_et_al_2012_an_error-tolerant_type_system_for_variational_lambda_calculus.pdf:application/pdf}
}

@inproceedings{perera_functional_2012,
	address = {New York, NY, USA},
	series = {{ICFP} '12},
	title = {Functional {Programs} {That} {Explain} {Their} {Work}},
	isbn = {978-1-4503-1054-3},
        doi = {10.1145/2364527.2364579},
	abstract = {We present techniques that enable higher-order functional computations to "explain" their work by answering questions about how parts of their output were calculated. As explanations, we consider the traditional notion of program slices, which we show can be inadequate, and propose a new notion: trace slices. We present techniques for specifying flexible and rich slicing criteria based on partial expressions, parts of which have been replaced by holes. We characterise program slices in an algorithm-independent fashion and show that a least slice for a given criterion exists. We then present an algorithm, called unevaluation, for computing least program slices from computations reified as traces. Observing a limitation of program slices, we develop a notion of trace slice as another form of explanation and present an algorithm for computing them. The unevaluation algorithm can be applied to any subtrace of a trace slice to compute a program slice whose evaluation generates that subtrace. This close correspondence between programs, traces, and their slices can enable the programmer to understand a computation interactively, in terms of the programming language in which the computation is expressed. We present an implementation in the form of a tool, discuss some important practical implementation concerns and present some techniques for addressing them.},
	urldate = {2015-01-08},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Perera, Roly and Acar, Umut A. and Cheney, James and Levy, Paul Blain},
	year = {2012},
	keywords = {debugging, program slicing, provenance},
	pages = {365--376},
	file = {perera_et_al_2012_functional_programs_that_explain_their_work.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/T49TERWH/perera_et_al_2012_functional_programs_that_explain_their_work.pdf:application/pdf;perera_et_al_2012_functional_programs_that_explain_their_work.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/RCZUAB42/perera_et_al_2012_functional_programs_that_explain_their_work.pdf:application/pdf}
}

@incollection{sparud_tracing_1997,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Tracing lazy functional computations using redex trails},
	copyright = {©1997 Springer-Verlag},
	isbn = {978-3-540-63398-3 978-3-540-69537-0},
	url = {http://link.springer.com/chapter/10.1007/BFb0033851},
	abstract = {We describe the design and implementation of a system for tracing computations in a lazy functional language. The basis of our tracing method is a program transformation carried out by the compiler: transformed programs compute the same values as the original, but embedded in functional data structures that also include redex trails showing how the values were obtained. A special-purpose display program enables detailed but selective exploration of the redex trails, with cross-links to the source program.},
	language = {en},
	number = {1292},
	urldate = {2015-10-29},
	booktitle = {Programming {Languages}: {Implementations}, {Logics}, and {Programs}},
	publisher = {Springer Berlin Heidelberg},
	author = {Sparud, Jan and Runciman, Colin},
	editor = {Glaser, Hugh and Hartel, Pieter and Kuchen, Herbert},
	month = sep,
	year = {1997},
	note = {DOI: 10.1007/BFb0033851},
	keywords = {Artificial Intelligence (incl. Robotics), debugging, graph reduction, haskell, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, program transformation},
	pages = {291--308},
	file = {Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/X5PFGIQ9/10.html:text/html;sparud_runciman_1997_tracing_lazy_functional_computations_using_redex_trails.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/PR2PPASK/sparud_runciman_1997_tracing_lazy_functional_computations_using_redex_trails.pdf:application/pdf}
}

@incollection{reinking_type-directed_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Type}-{Directed} {Approach} to {Program} {Repair}},
	copyright = {©2015 Springer International Publishing Switzerland},
	isbn = {978-3-319-21689-8 978-3-319-21690-4},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-21690-4_35},
	abstract = {Developing enterprise software often requires composing several libraries together with a large body of in-house code. Large APIs introduce a steep learning curve for new developers as a result of their complex object-oriented underpinnings. While the written code in general reflects a programmer’s intent, due to evolutions in an API, code can often become ill-typed, yet still syntactically-correct. Such code fragments will no longer compile, and will need to be updated. We describe an algorithm that automatically repairs such errors, and discuss its application to common problems in software engineering.},
	language = {en},
	number = {9206},
	urldate = {2015-11-12},
	booktitle = {Computer {Aided} {Verification}},
	publisher = {Springer International Publishing},
	author = {Reinking, Alex and Piskac, Ruzica},
	editor = {Kroening, Daniel and Păsăreanu, Corina S.},
	month = jul,
	year = {2015},
	note = {DOI: 10.1007/978-3-319-21690-4\_35},
	keywords = {Computer Systems Organization and Communication Networks, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Software Engineering/Programming and Operating Systems},
	pages = {511--517},
	file = {reinking_piskac_2015_a_type-directed_approach_to_program_repair.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/GFDJEUZ3/reinking_piskac_2015_a_type-directed_approach_to_program_repair.pdf:application/pdf;Snapshot:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/X5RWHSMD/978-3-319-21690-4_35.html:text/html}
}

@incollection{chang_stack_2012,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {From {Stack} {Traces} to {Lazy} {Rewriting} {Sequences}},
	copyright = {©2012 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-642-34406-0 978-3-642-34407-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-34407-7_7},
	abstract = {Reasoning about misbehaving lazy functional programs can be confusing, particularly for novice programmers. Unfortunately, the complicated nature of laziness also renders most debugging tools ineffective at clarifying this confusion. In this paper, we introduce a new lazy debugging tool for novice programmers, an algebraic stepper that presents computation as a sequence of parallel rewriting steps. Parallel program rewriting represents sharing accurately and enables debugging at the level of source syntax, minimizing the presentation of low-level details or the effects of distorting transformations that are typical for other lazy debuggers. Semantically, our rewriting system represents a compromise between Launchbury’s store-based semantics and an axiomatic description of lazy computation as sharing-via-parameters. Finally, we prove the correctness of our tool by showing that the stepper’s run-time machinery reconstructs the expected lazy rewriting sequence.},
	language = {en},
	number = {7257},
	urldate = {2015-05-29},
	booktitle = {Implementation and {Application} of {Functional} {Languages}},
	publisher = {Springer Berlin Heidelberg},
	author = {Chang, Stephen and Barzilay, Eli and Clements, John and Felleisen, Matthias},
	editor = {Gill, Andy and Hage, Jurriaan},
	year = {2012},
	keywords = {debugging, lazy lambda calculus, lazy programming, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {100--115},
	file = {chang_et_al_2012_from_stack_traces_to_lazy_rewriting_sequences.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/XEB7RDDG/chang_et_al_2012_from_stack_traces_to_lazy_rewriting_sequences.pdf:application/pdf}
}

@inproceedings{zhang_diagnosing_2015,
	address = {New York, NY, USA},
	series = {{PLDI} 2015},
	title = {Diagnosing {Type} {Errors} with {Class}},
	isbn = {978-1-4503-3468-6},
	url = {http://doi.acm.org/10.1145/2737924.2738009},
	doi = {10.1145/2737924.2738009},
	abstract = {Type inference engines often give terrible error messages, and the more sophisticated the type system the worse the problem. We show that even with the highly expressive type system implemented by the Glasgow Haskell Compiler (GHC)--including type classes, GADTs, and type families--it is possible to identify the most likely source of the type error, rather than the first source that the inference engine trips over. To determine which are the likely error sources, we apply a simple Bayesian model to a graph representation of the typing constraints; the satisfiability or unsatisfiability of paths within the graph provides evidence for or against possible explanations. While we build on prior work on error diagnosis for simpler type systems, inference in the richer type system of Haskell requires extending the graph with new nodes. The augmentation of the graph creates challenges both for Bayesian reasoning and for ensuring termination. Using a large corpus of Haskell programs, we show that this error localization technique is practical and significantly improves accuracy over the state of the art.},
	urldate = {2015-06-15},
	booktitle = {Proceedings of the 36th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Zhang, Danfeng and Myers, Andrew C. and Vytiniotis, Dimitrios and Peyton-Jones, Simon},
	year = {2015},
	keywords = {error diagnosis, haskell, type inference},
	pages = {12--21},
	file = {zhang_et_al_2015_diagnosing_type_errors_with_class.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/SKZHE8K8/zhang_et_al_2015_diagnosing_type_errors_with_class.pdf:application/pdf}
}

@inproceedings{faddegon_algorithmic_2015,
	address = {New York, NY, USA},
	series = {{PLDI} 2015},
	title = {Algorithmic {Debugging} of {Real}-world {Haskell} {Programs}: {Deriving} {Dependencies} from the {Cost} {Centre} {Stack}},
	isbn = {978-1-4503-3468-6},
	shorttitle = {Algorithmic {Debugging} of {Real}-world {Haskell} {Programs}},
	url = {http://doi.acm.org/10.1145/2737924.2737985},
	doi = {10.1145/2737924.2737985},
	abstract = {Existing algorithmic debuggers for Haskell require a transformation of all modules in a program, even libraries that the user does not want to debug and which may use language features not supported by the debugger. This is a pity, because a promising approach to debugging is therefore not applicable to many real-world programs. We use the cost centre stack from the Glasgow Haskell Compiler profiling environment together with runtime value observations as provided by the Haskell Object Observation Debugger (HOOD) to collect enough information for algorithmic debugging. Program annotations are in suspected modules only. With this technique algorithmic debugging is applicable to a much larger set of Haskell programs. This demonstrates that for functional languages in general a simple stack trace extension is useful to support tasks such as profiling and debugging.},
	urldate = {2015-06-15},
	booktitle = {Proceedings of the 36th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Faddegon, Maarten and Chitil, Olaf},
	year = {2015},
	keywords = {algorithmic debugging, haskell, lazy evaluation, tracing},
	pages = {33--42},
	file = {faddegon_chitil_2015_algorithmic_debugging_of_real-world_haskell_programs.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/ISGETC9E/faddegon_chitil_2015_algorithmic_debugging_of_real-world_haskell_programs.pdf:application/pdf}
}

@inproceedings{isradisaikul_finding_2015,
	address = {New York, NY, USA},
	series = {{PLDI} 2015},
	title = {Finding {Counterexamples} from {Parsing} {Conflicts}},
	isbn = {978-1-4503-3468-6},
	url = {http://doi.acm.org/10.1145/2737924.2737961},
	doi = {10.1145/2737924.2737961},
	abstract = {Writing a parser remains remarkably painful. Automatic parser generators offer a powerful and systematic way to parse complex grammars, but debugging conflicts in grammars can be time-consuming even for experienced language designers. Better tools for diagnosing parsing conflicts will alleviate this difficulty. This paper proposes a practical algorithm that generates compact, helpful counterexamples for LALR grammars. For each parsing conflict in a grammar, a counterexample demonstrating the conflict is constructed. When the grammar in question is ambiguous, the algorithm usually generates a compact counterexample illustrating the ambiguity. This algorithm has been implemented as an extension to the CUP parser generator. The results from applying this implementation to a diverse collection of faulty grammars show that the algorithm is practical, effective, and suitable for inclusion in other LALR parser generators.},
	urldate = {2015-06-15},
	booktitle = {Proceedings of the 36th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Isradisaikul, Chinawat and Myers, Andrew C.},
	year = {2015},
	keywords = {ambiguous grammar, Context-free grammar, error diagnosis, lookahead-sensitive path, product parser, shift-reduce parser},
	pages = {555--564},
	file = {isradisaikul_myers_2015_finding_counterexamples_from_parsing_conflicts.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/IUBMPMRF/isradisaikul_myers_2015_finding_counterexamples_from_parsing_conflicts.pdf:application/pdf}
}

@inproceedings{manevich_pse:_2004,
	address = {New York, NY, USA},
	series = {{SIGSOFT} '04/{FSE}-12},
	title = {{PSE}: {Explaining} {Program} {Failures} via {Postmortem} {Static} {Analysis}},
	isbn = {1-58113-855-5},
	shorttitle = {{PSE}},
	url = {http://doi.acm.org/10.1145/1029894.1029907},
	doi = {10.1145/1029894.1029907},
	abstract = {In this paper, we describe PSE (Postmortem Symbolic Evaluation), a static analysis algorithm that can be used by programmers to diagnose software failures. The algorithm requires minimal information about a failure, namely its kind (e.g. NULL dereference), and its location in the program's source code. It produces a set of execution traces along which the program can be driven to the given failure. PSE tracks the flow of a single value of interest from the point in the program where the failure occurred back to the points in the program where the value may have originated. The algorithm combines a novel dataflow analysis and memory alias analysis in a manner that allows for precise exploration of the program's behavior in polynomial time. We have applied PSE to the problem of diagnosing potential NULL-dereference errors in a suite of C programs, including several SPEC benchmarks and a large commercial operating system. In most cases, the analysis is able to either validate a pointer dereference, or find precise error traces demonstrating a NULL value for the pointer, in less than a second.},
	urldate = {2015-06-23},
	booktitle = {Proceedings of the 12th {ACM} {SIGSOFT} {Twelfth} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Manevich, Roman and Sridharan, Manu and Adams, Stephen and Das, Manuvir and Yang, Zhe},
	year = {2004},
	keywords = {alias analysis, postmortem analysis, typestate, value flow},
	pages = {63--72},
	file = {manevich_et_al_2004_pse.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/7ZJX4H8A/manevich_et_al_2004_pse.pdf:application/pdf}
}

@inproceedings{lerner_searching_2007,
	address = {New York, NY, USA},
	series = {{PLDI} '07},
	title = {Searching for {Type}-error {Messages}},
	isbn = {978-1-59593-633-2},
        doi = {10.1145/1250734.1250783},
	abstract = {Advanced type systems often need some form of type inference to reduce the burden of explicit typing, but type inference often leads to poor error messages for ill-typed programs. This work pursues a new approach to constructing compilers and presenting type-error messages in which the type-checker itself does not produce the messages. Instead, it is an oracle for a search procedure that finds similar programs that do type-check. Our two-fold goal is to improve error messages while simplifying compiler construction. Our primary implementation and evaluation is for Caml, a language with full type inference. We also present a prototype for C++ template functions, where type instantiation is implicit. A key extension is making our approach robust even when the program has multiple independent type errors.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 28th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Lerner, Benjamin S. and Flower, Matthew and Grossman, Dan and Chambers, Craig},
	year = {2007},
	keywords = {error messages, objective Caml, seminal, type-checking, type-inference},
	pages = {425--434},
	file = {lerner_et_al_2007_searching_for_type-error_messages.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/FMIQF8AW/lerner_et_al_2007_searching_for_type-error_messages.pdf:application/pdf}
}

@inproceedings{lerner_seminal:_2006,
	address = {New York, NY, USA},
	series = {{ML} '06},
	title = {Seminal: {Searching} for {ML} {Type}-error {Messages}},
	isbn = {1-59593-483-9},
	shorttitle = {Seminal},
        doi = {10.1145/1159876.1159887},
	abstract = {We present a new way to generate type-error messages in a polymorphic, implicitly, and strongly typed language (specifically Caml). Our method separates error-message generation from type-checking by taking a fundamentally new approach: we present to programmers small term-level modifications that cause an ill-typed program to become well-typed. This approach aims to improve feedback to programmers with no change to the underlying type-checker nor the compilation of well-typed programs.We have added a prototype implementation of our approach to the Objective Caml system by intercepting type-checker error messages and using the type-checker on candidate changes to see if they succeed. This novel front-end architecture naturally decomposes into (1) enumerating local changes to the abstract syntax tree that may remove type errors, (2) searching for places to try the changes, (3) using the type-checker to evaluate the changes, and (4) ranking the changes and presenting them to the user.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 2006 {Workshop} on {ML}},
	publisher = {ACM},
	author = {Lerner, Benjamin and Grossman, Dan and Chambers, Craig},
	year = {2006},
	keywords = {error messages, objective Caml, seminal, type-checking, type-inference},
	pages = {63--73},
	file = {lerner_et_al_2006_seminal.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/6ZKTKVM7/lerner_et_al_2006_seminal.pdf:application/pdf}
}

@inproceedings{chitil_typeview:_2000,
	title = {Typeview: a tool for understanding type errors},
	shorttitle = {Typeview},
	abstract = {Abstract. In modern statically typed functional languages, type inference is used to determine the type of each function automatically. Whenever this fails, the compiler emits an error message that is often very complex. Sometimes the expression mentioned in the type error message is not the one that is wrong. We therefore implement an interactive tool that allows programmers to browse through the source code of their program and query the types of each expression. If a variable cannot be typed, we would like to present a set of possible types from which the user can decide which is wrong. This should help finding the origin of type errors without detailed knowledge of type inference on the user side. 1},
	booktitle = {12th {International} {Workshop} on {Implementation} of {Functional} {Languages}, {Aachner} {Informatik}-{Berichte}},
	author = {Chitil, Olaf and Huch, Frank and Simon, Axel},
	year = {2000},
	pages = {63--69},
	file = {chitil_et_al_2000_typeview.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/A6S9JF9Q/chitil_et_al_2000_typeview.pdf:application/pdf}
}

@incollection{haack_type_2003,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Type {Error} {Slicing} in {Implicitly} {Typed} {Higher}-{Order} {Languages}},
	copyright = {©2003 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-00886-6 978-3-540-36575-4},
	url = {http://link.springer.com/chapter/10.1007/3-540-36575-3_20},
	abstract = {Previous methods have generally identified the location of a type error as a particular program point or the program subtree rooted at that point. We present a new approach that identifies the location of a type error as a set of program points (a slice) all of which are necessary for the type error. We describe algorithms for finding minimal type error slices for implicitly typed higher-order languages like Standard ML.},
	language = {en},
	number = {2618},
	urldate = {2015-06-26},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Haack, Christian and Wells, J. B.},
	editor = {Degano, Pierpaolo},
	year = {2003},
	keywords = {data structures, Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {284--301},
	file = {haack_wells_2003_type_error_slicing_in_implicitly_typed_higher-order_languages.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/K8AVH5ZV/haack_wells_2003_type_error_slicing_in_implicitly_typed_higher-order_languages.pdf:application/pdf}
}

@inproceedings{sen_cute:_2005,
	address = {New York, NY, USA},
	series = {{ESEC}/{FSE}-13},
	title = {{CUTE}: {A} {Concolic} {Unit} {Testing} {Engine} for {C}},
	isbn = {1-59593-014-0},
	shorttitle = {{CUTE}},
	url = {http://doi.acm.org/10.1145/1081706.1081750},
	doi = {10.1145/1081706.1081750},
	abstract = {In unit testing, a program is decomposed into units which are collections of functions. A part of unit can be tested by generating inputs for a single entry function. The entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. The paper addresses the problem of automating unit testing with memory graphs as inputs. The approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. The current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. Moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. Finally, CUTE, a tool implementing the method is described together with the results of applying CUTE to real-world examples of C code.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 10th {European} {Software} {Engineering} {Conference} {Held} {Jointly} with 13th {ACM} {SIGSOFT} {International} {Symposium} on {Foundations} of {Software} {Engineering}},
	publisher = {ACM},
	author = {Sen, Koushik and Marinov, Darko and Agha, Gul},
	year = {2005},
	keywords = {concolic testing, data structure testing, explicit path model-checking, random testing, testing C programs, unit testing},
	pages = {263--272},
	file = {sen_et_al_2005_cute.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/9F5NHKNV/sen_et_al_2005_cute.pdf:application/pdf}
}

@inproceedings{godefroid_dart:_2005,
	address = {New York, NY, USA},
	series = {{PLDI} '05},
	title = {{DART}: {Directed} {Automated} {Random} {Testing}},
	isbn = {1-59593-056-6},
	shorttitle = {{DART}},
        doi = {10.1145/1065010.1065036},
	abstract = {We present a new tool, named DART, for automatically testing software that combines three main techniques: (1) automated extraction of the interface of a program with its external environment using static source-code parsing; (2) automatic generation of a test driver for this interface that performs random testing to simulate the most general environment the program can operate in; and (3) dynamic analysis of how the program behaves under random testing and automatic generation of new test inputs to direct systematically the execution along alternative program paths. Together, these three techniques constitute Directed Automated Random Testing, or DART for short. The main strength of DART is thus that testing can be performed completely automatically on any program that compiles -- there is no need to write any test driver or harness code. During testing, DART detects standard errors such as program crashes, assertion violations, and non-termination. Preliminary experiments to unit test several examples of C programs are very encouraging.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 2005 {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Godefroid, Patrice and Klarlund, Nils and Sen, Koushik},
	year = {2005},
	keywords = {automated test generation, interfaces, program verification, random testing, software testing},
	pages = {213--223},
	file = {godefroid_et_al_2005_dart.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/9ZTJ7DXR/godefroid_et_al_2005_dart.pdf:application/pdf}
}

@inproceedings{ko_designing_2004,
	address = {New York, NY, USA},
	series = {{CHI} '04},
	title = {Designing the {Whyline}: {A} {Debugging} {Interface} for {Asking} {Questions} {About} {Program} {Behavior}},
	isbn = {1-58113-702-8},
	shorttitle = {Designing the {Whyline}},
	url = {http://doi.acm.org/10.1145/985692.985712},
	doi = {10.1145/985692.985712},
	abstract = {Debugging is still among the most common and costly of programming activities. One reason is that current debugging tools do not directly support the inquisitive nature of the activity. Interrogative Debugging is a new debugging paradigm in which programmers can ask why did and even why didn't questions directly about their program's runtime failures. The Whyline is a prototype Interrogative Debugging interface for the Alice programming environment that visualizes answers in terms of runtime events directly relevant to a programmer's question. Comparisons of identical debugging scenarios from user tests with and without the Whyline showed that the Whyline reduced debugging time by nearly a factor of 8, and helped programmers complete 40\% more tasks.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the {SIGCHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
	publisher = {ACM},
	author = {Ko, Andrew J. and Myers, Brad A.},
	year = {2004},
	keywords = {Alice, debugging, program slicing},
	pages = {151--158},
	file = {ko_myers_2004_designing_the_whyline.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/QC9D6U8I/ko_myers_2004_designing_the_whyline.pdf:application/pdf}
}

@inproceedings{duregard_feat:_2012,
	address = {New York, NY, USA},
	series = {Haskell '12},
	title = {Feat: {Functional} {Enumeration} of {Algebraic} {Types}},
	isbn = {978-1-4503-1574-6},
	shorttitle = {Feat},
	url = {http://doi.acm.org/10.1145/2364506.2364515},
	doi = {10.1145/2364506.2364515},
	abstract = {In mathematics, an enumeration of a set S is a bijective function from (an initial segment of) the natural numbers to S. We define "functional enumerations" as efficiently computable such bijections. This paper describes a theory of functional enumeration and provides an algebra of enumerations closed under sums, products, guarded recursion and bijections. We partition each enumerated set into numbered, finite subsets. We provide a generic enumeration such that the number of each part corresponds to the size of its values (measured in the number of constructors). We implement our ideas in a Haskell library called testing-feat, and make the source code freely available. Feat provides efficient "random access" to enumerated values. The primary application is property-based testing, where it is used to define both random sampling (for example QuickCheck generators) and exhaustive enumeration (in the style of SmallCheck). We claim that functional enumeration is the best option for automatically generating test cases from large groups of mutually recursive syntax tree types. As a case study we use Feat to test the pretty-printer of the Template Haskell library (uncovering several bugs).},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 2012 {Haskell} {Symposium}},
	publisher = {ACM},
	author = {Duregård, Jonas and Jansson, Patrik and Wang, Meng},
	year = {2012},
	keywords = {enumeration, memoisation, property-based testing},
	pages = {61--72},
	file = {duregård_et_al_2012_feat.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/7HE7BKK2/duregård_et_al_2012_feat.pdf:application/pdf}
}

@incollection{claessen_generating_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Generating {Constrained} {Random} {Data} with {Uniform} {Distribution}},
	copyright = {©2014 Springer International Publishing Switzerland},
	isbn = {978-3-319-07150-3 978-3-319-07151-0},
	url = {http://link.springer.com/chapter/10.1007/978-3-319-07151-0_2},
	abstract = {We present a technique for automatically deriving test data generators from a predicate expressed as a Boolean function. The distribution of these generators is uniform over values of a given size. To make the generation efficient we rely on laziness of the predicate, allowing us to prune the space of values quickly. In contrast, implementing test data generators by hand is labour intensive and error prone. Moreover, handwritten generators often have an unpredictable distribution of values, risking that some values are arbitrarily underrepresented. We also present a variation of the technique where the distribution is skewed in a limited and predictable way, potentially increasing the performance. Experimental evaluation of the techniques shows that the uniform derived generators are much easier to define than hand-written ones, and their performance, while lower, is adequate for some realistic applications.},
	language = {en},
	number = {8475},
	urldate = {2015-06-26},
	booktitle = {Functional and {Logic} {Programming}},
	publisher = {Springer International Publishing},
	author = {Claessen, Koen and Duregård, Jonas and Pałka, Michał H.},
	editor = {Codish, Michael and Sumii, Eijiro},
	month = jun,
	year = {2014},
	keywords = {Artificial Intelligence (incl. Robotics), Logics and Meanings of Programs, Mathematical Logic and Formal Languages, Programming Languages, Compilers, Interpreters, Programming Techniques, Software Engineering},
	pages = {18--34},
	file = {claessen_et_al_2014_generating_constrained_random_data_with_uniform_distribution.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/AKKI939H/claessen_et_al_2014_generating_constrained_random_data_with_uniform_distribution.pdf:application/pdf}
}

@article{csallner_jcrasher:_2004,
	title = {{JCrasher}: an automatic robustness tester for {Java}},
	volume = {34},
	copyright = {Copyright © 2004 John Wiley \& Sons, Ltd.},
	issn = {1097-024X},
	shorttitle = {{JCrasher}},
        doi = {10.1002/spe.602},
	abstract = {JCrasher is an automatic robustness testing tool for Java code. JCrasher examines the type information of a set of Java classes and constructs code fragments that will create instances of different types to test the behavior of public methods under random data. JCrasher attempts to detect bugs by causing the program under test to ‘crash’, that is, to throw an undeclared runtime exception. Although in general the random testing approach has many limitations, it also has the advantage of being completely automatic: o supervision is required except for off-line inspection of the test ases that have caused a crash. Compared to other similar commercial and research tools, JCrasher offers several novelties: it transitively analyzes methods, determines the size of each tested method's parameter-space and selects parameter combinations and therefore test cases at random, taking into account the time allocated for testing; it defines heuristics for determining whether a Java exception should be considered as a program bug or whether the JCrasher supplied inputs have violated the code's preconditions; it includes support for efficiently undoing all the state changes introduced by previous tests; it produces test files for JUnit, a popular Java testing tool; and it can be integrated in the Eclipse IDE. Copyright © 2004 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {11},
	urldate = {2015-06-26},
	journal = {Software: Practice and Experience},
	author = {Csallner, Christoph and Smaragdakis, Yannis},
	month = sep,
	year = {2004},
	keywords = {Java, random testing, software testing, state re-initialization, test case generation},
	pages = {1025--1050},
	file = {csallner_smaragdakis_2004_jcrasher.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/HF779R5P/csallner_smaragdakis_2004_jcrasher.pdf:application/pdf}
}

@inproceedings{boyapati_korat:_2002,
	address = {New York, NY, USA},
	series = {{ISSTA} '02},
	title = {Korat: {Automated} {Testing} {Based} on {Java} {Predicates}},
	isbn = {1-58113-562-9},
	shorttitle = {Korat},
	url = {http://doi.acm.org/10.1145/566172.566191},
	doi = {10.1145/566172.566191},
	abstract = {This paper presents Korat, a novel framework for automated testing of Java programs. Given a formal specification for a method, Korat uses the method precondition to automatically generate all (nonisomorphic) test cases up to a given small size. Korat then executes the method on each test case, and uses the method postcondition as a test oracle to check the correctness of each output.To generate test cases for a method, Korat constructs a Java predicate (i.e., a method that returns a boolean) from the method's pre-condition. The heart of Korat is a technique for automatic test case generation: given a predicate and a bound on the size of its inputs, Korat generates all (nonisomorphic) inputs for which the predicate returns true. Korat exhaustively explores the bounded input space of the predicate but does so efficiently by monitoring the predicate's executions and pruning large portions of the search space.This paper illustrates the use of Korat for testing several data structures, including some from the Java Collections Framework. The experimental results show that it is feasible to generate test cases from Java predicates, even when the search space for inputs is very large. This paper also compares Korat with a testing framework based on declarative specifications. Contrary to our initial expectation, the experiments show that Korat generates test cases much faster than the declarative framework.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 2002 {ACM} {SIGSOFT} {International} {Symposium} on {Software} {Testing} and {Analysis}},
	publisher = {ACM},
	author = {Boyapati, Chandrasekhar and Khurshid, Sarfraz and Marinov, Darko},
	year = {2002},
	pages = {123--133},
	file = {boyapati_et_al_2002_korat.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/JR5RA9FS/boyapati_et_al_2002_korat.pdf:application/pdf}
}

@inproceedings{ramsey_teaching_2014,
	address = {New York, NY, USA},
	series = {{ICFP} '14},
	title = {On {Teaching} *{How} to {Design} {Programs}*: {Observations} from a {Newcomer}},
	isbn = {978-1-4503-2873-9},
	shorttitle = {On {Teaching} *{How} to {Design} {Programs}*},
	url = {http://doi.acm.org/10.1145/2628136.2628137},
	doi = {10.1145/2628136.2628137},
	abstract = {This paper presents a personal, qualitative case study of a first course using How to Design Programs and its functional teaching languages. The paper reconceptualizes the book's six-step design process as an eight-step design process ending in a new "review and refactor" step. It recommends specific approaches to students' difficulties with function descriptions, function templates, data examples, and other parts of the design process. It connects the process to interactive "world programs." It recounts significant, informative missteps in course design and delivery. Finally, it identifies some unsolved teaching problems and some potential solutions.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the 19th {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Ramsey, Norman},
	year = {2014},
	keywords = {how to design programs, introductory programming course, program by design, racket, reflective practice},
	pages = {153--166},
	file = {ramsey_2014_on_teaching_how_to_design_programs.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/NVQTGSG6/ramsey_2014_on_teaching_how_to_design_programs.pdf:application/pdf}
}

@incollection{tillmann_pex_2008,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Pex - {White} {Box} {Test} {Generation} for .{NET}},
	copyright = {©2008 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-79123-2 978-3-540-79124-9},
	url = {http://link.springer.com/chapter/10.1007/978-3-540-79124-9_10},
	abstract = {Pex automatically produces a small test suite with high code coverage for a .NET program. To this end, Pex performs a systematic program analysis (using dynamic symbolic execution, similar to path-bounded model-checking) to determine test inputs for Parameterized Unit Tests. Pex learns the program behavior by monitoring execution traces. Pex uses a constraint solver to produce new test inputs which exercise different program behavior. The result is an automatically generated small test suite which often achieves high code coverage. In one case study, we applied Pex to a core component of the .NET runtime which had already been extensively tested over several years. Pex found errors, including a serious issue.},
	language = {en},
	number = {4966},
	urldate = {2015-06-26},
	booktitle = {Tests and {Proofs}},
	publisher = {Springer Berlin Heidelberg},
	author = {Tillmann, Nikolai and Halleux, Jonathan de},
	editor = {Beckert, Bernhard and Hähnle, Reiner},
	year = {2008},
	keywords = {Computer Communication Networks, Computers and Society, Logics and Meanings of Programs, Software Engineering, System Performance and Evaluation},
	pages = {134--153},
	file = {tillmann_halleux_2008_pex–white_box_test_generation_for.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/G553QAXB/tillmann_halleux_2008_pex–white_box_test_generation_for.pdf:application/pdf}
}

@inproceedings{claessen_quickcheck:_2000,
	address = {New York, NY, USA},
	series = {{ICFP} '00},
	title = {{QuickCheck}: {A} {Lightweight} {Tool} for {Random} {Testing} of {Haskell} {Programs}},
	isbn = {1-58113-202-6},
	shorttitle = {{QuickCheck}},
        doi = {10.1145/351240.351266},
	abstract = {Quick Check is a tool which aids the Haskell programmer in formulating and testing properties of programs. Properties are described as Haskell functions, and can be automatically tested on random input, but it is also possible to define custom test data generators. We present a number of case studies, in which the tool was successfully used, and also point out some pitfalls to avoid. Random testing is especially suitable for functional programs because properties can be stated at a fine grain. When a function is built from separately tested components, then random testing suffices to obtain good coverage of the definition under test.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the {Fifth} {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {ACM},
	author = {Claessen, Koen and Hughes, John},
	year = {2000},
	pages = {268--279},
	file = {claessen_hughes_2000_quickcheck.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/25N4HZQJ/claessen_hughes_2000_quickcheck.pdf:application/pdf}
}

@inproceedings{runciman_smallcheck_2008,
	address = {New York, NY, USA},
	series = {Haskell '08},
	title = {Smallcheck and {Lazy} {Smallcheck}: {Automatic} {Exhaustive} {Testing} for {Small} {Values}},
	isbn = {978-1-60558-064-7},
	shorttitle = {Smallcheck and {Lazy} {Smallcheck}},
        doi = {10.1145/1411286.1411292},
	abstract = {This paper describes two Haskell libraries for property-based testing. Following the lead of QuickCheck, these testing libraries SmallCheck and Lazy SmallCheck also use type-based generators to obtain test-sets of finite values for which properties are checked, and report any counter-examples found. But instead of using a sample of randomly generated values they test properties for all values up to some limiting depth, progressively increasing this limit. The paper explains the design and implementation of both libraries and evaluates them in comparison with each other and with QuickCheck.},
	urldate = {2015-06-26},
	booktitle = {Proceedings of the {First} {ACM} {SIGPLAN} {Symposium} on {Haskell}},
	publisher = {ACM},
	author = {Runciman, Colin and Naylor, Matthew and Lindblad, Fredrik},
	year = {2008},
	keywords = {embedded language, exhaustive search, lazy evaluation, property-based testing, type classes},
	pages = {37--48},
	file = {runciman_et_al_2008_smallcheck_and_lazy_smallcheck.pdf:/Users/gridaphobe/Library/Application Support/Firefox/Profiles/f18czy5l.default/zotero/storage/W58WX5BF/runciman_et_al_2008_smallcheck_and_lazy_smallcheck.pdf:application/pdf}
}

@book{felleisen2009semantics,
  title={Semantics engineering with PLT Redex},
  author={Felleisen, Matthias and Findler, Robert Bruce and Flatt, Matthew},
  year={2009},
  publisher={The MIT Press}
}
