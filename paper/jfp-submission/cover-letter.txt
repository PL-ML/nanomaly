For the JFP Special Issue we have focused on extending our experimental
evaluation. In particular, we have added two brand new sections to the
evaluation.

5.3: How safe are the “safe” programs?
In this section we investigate the student programs where we were unable
to synthesize a witness. We group the failures into five categories,
give representative examples, and suggest ways to improve our feedback
in these cases. Interestingly, we find that in the majority of these
failed cases, the programs do not actually admit a witness in our
semantics.

5.7 Locating Errors with Witnesses
In this section we attempt to use our witnesses to localize type errors
with a simple heuristic. We treat the stuck term as a sink for typing
constraints, and the values it contains as sources of constraints. We
can then predict that either the stuck term or one of the terms that
*produced* a value it contains is likely at fault for the error. We
compare our localizations to OCaml and two state-of-the-art type error
localization tools, and find that we are competitive with the state of
the art.

We have also extended section 5.6 with an analysis of the statistical
significance of our user study results.
